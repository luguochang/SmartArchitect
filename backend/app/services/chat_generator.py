import json
import logging
from pathlib import Path
from typing import List, Optional, Tuple, Any

from fastapi import HTTPException
from app.api.mermaid import parse_mermaid_to_graph, graph_to_mermaid
from app.models.schemas import (
    FlowTemplate,
    FlowTemplateList,
    ChatGenerationRequest,
    ChatGenerationResponse,
    Node,
    Edge,
)
from app.services.ai_vision import create_vision_service
from app.services.model_presets import get_model_presets_service

logger = logging.getLogger(__name__)


# Architecture type templates configuration
ARCHITECTURE_TEMPLATES = {
    "layered": {
        "name": "åˆ†å±‚æ¶æ„",
        "name_en": "Layered Architecture",
        "layers": ["frontend", "backend", "middleware", "data", "infrastructure"],
        "default_columns": 5,
        "show_edges": False,
        "description": "é€šç”¨å‰åç«¯åˆ†å±‚æ¶æ„ï¼Œé€‚ç”¨äºWebåº”ç”¨ã€å¾®æœåŠ¡ç­‰",
    },
    "business": {
        "name": "ä¸šåŠ¡æ¶æ„",
        "name_en": "Business Architecture",
        "layers": ["capability", "service", "process", "organization"],
        "default_columns": 6,
        "show_edges": False,  # Business architecture focuses on layers, not connections
        "description": "ä¸šåŠ¡èƒ½åŠ›åœ°å›¾ï¼Œå±•ç¤ºä¼ä¸šèƒ½åŠ›ã€æœåŠ¡ã€æµç¨‹å’Œç»„ç»‡å…³ç³»",
    },
    "technical": {
        "name": "æŠ€æœ¯æ¶æ„",
        "name_en": "Technical Architecture",
        "layers": ["presentation", "application", "integration", "data", "infrastructure"],
        "default_columns": 5,
        "show_edges": True,  # Technical architecture shows API calls and data flow
        "edge_type": "data-flow",
        "description": "æŠ€æœ¯ç³»ç»Ÿæ¶æ„ï¼Œå±•ç¤ºåº”ç”¨ç»„ä»¶ä¹‹é—´çš„æŠ€æœ¯ä¾èµ–å’Œæ•°æ®æµ",
    },
    "deployment": {
        "name": "éƒ¨ç½²æ¶æ„",
        "name_en": "Deployment Architecture",
        "layers": ["dmz", "app-tier", "data-tier", "monitoring"],
        "default_columns": 4,
        "show_edges": True,  # Deployment shows network connectivity
        "edge_type": "network",
        "description": "åŸºç¡€è®¾æ–½éƒ¨ç½²æ¶æ„ï¼Œå±•ç¤ºç½‘ç»œæ‹“æ‰‘ã€æœåŠ¡å™¨ã€å®¹å™¨ç¼–æ’",
    },
    "domain": {
        "name": "é¢†åŸŸæ¶æ„",
        "name_en": "Domain-Driven Architecture",
        "layers": ["domain-services", "shared-kernel", "anti-corruption", "infrastructure"],
        "default_columns": 4,
        "show_edges": True,
        "edge_type": "dependency",
        "description": "é¢†åŸŸé©±åŠ¨è®¾è®¡æ¶æ„ï¼Œå±•ç¤ºæœ‰ç•Œä¸Šä¸‹æ–‡å’Œé¢†åŸŸæœåŠ¡",
    },
}


class ChatGeneratorService:
    """Chat-based flowchart generation service (mock-first)."""

    def __init__(self):
        self.templates_path = Path(__file__).parent.parent / "data" / "flow_templates.json"
        self.templates: List[FlowTemplate] = []
        self._load_templates()

    def _load_templates(self):
        """Load templates from JSON file."""
        try:
            with open(self.templates_path, "r", encoding="utf-8") as f:
                data = json.load(f)
                self.templates = [FlowTemplate(**tpl) for tpl in data["templates"]]
            logger.info(f"Loaded {len(self.templates)} flow templates")
        except Exception as e:
            logger.error(f"Failed to load templates: {e}")
            self.templates = []

    def get_all_templates(self) -> FlowTemplateList:
        """Get all templates."""
        return FlowTemplateList(templates=self.templates)

    def get_template(self, template_id: str) -> Optional[FlowTemplate]:
        """Get template by ID."""
        for tpl in self.templates:
            if tpl.id == template_id:
                return tpl
        return None

    def _build_generation_prompt(self, request: ChatGenerationRequest) -> str:
        """Build generation prompt for flow or architecture diagrams."""
        template_context = ""
        if request.template_id:
            template = self.get_template(request.template_id)
            if template:
                template_context = f"""
Reference Template: {template.name}
Template Description: {template.description}
Example Input: "{template.example_input}"
Expected Style/Category: {template.category}

Please generate a similar flowchart following this template's style.
"""

        if request.diagram_type == "architecture":
            # Get architecture type template
            arch_type = request.architecture_type or "layered"
            template = ARCHITECTURE_TEMPLATES.get(arch_type, ARCHITECTURE_TEMPLATES["layered"])

            # Build layer-specific guidance with STRONG differentiation
            layer_examples = ""
            if arch_type == "business":
                layer_examples = """
**ğŸ¢ BUSINESS ARCHITECTURE - Focus on BUSINESS CAPABILITIES:**
CRITICAL: This is a BUSINESS view, NOT technical implementation!

**Required Layers (use EXACTLY these names):**
1. "capability" (èƒ½åŠ›å±‚) - 10-15 business capabilities
   - Examples: è®¿å®¢ç®¡ç†, è½¦è¾†ç®¡ç†, å®‰é˜²ç›‘æ§, èƒ½æºç®¡ç†, ç‰©ä¸šæœåŠ¡, æ™ºèƒ½æ¥¼å®‡, ç¯å¢ƒç›‘æµ‹, èµ„äº§ç®¡ç†, åº”æ€¥æŒ‡æŒ¥, æ•°æ®åˆ†æ, ç»Ÿä¸€è®¤è¯, æ¶ˆæ¯é€šçŸ¥
   - Use category: "service" for all capability items
   - NO tech stack - focus on WHAT the business does

2. "service" (æœåŠ¡å±‚) - 5-8 business service systems
   - Examples: è®¿å®¢é¢„çº¦ç³»ç»Ÿ, è½¦è¾†è¯†åˆ«ç³»ç»Ÿ, è§†é¢‘ç›‘æ§å¹³å°, èƒ½è€—åˆ†æå¹³å°, ç‰©ä¸šå·¥å•ç³»ç»Ÿ
   - Use category: "platform"
   - Add tech_stack ONLY if relevant to business stakeholders

3. "process" (æµç¨‹å±‚) - 3-5 key business processes
   - Examples: è®¿å®¢å…¥å›­æµç¨‹, è½¦è¾†è¿›å‡ºæµç¨‹, åº”æ€¥å“åº”æµç¨‹
   - Use category: "default"

4. "organization" (ç»„ç»‡å±‚) - 3-5 organizational units
   - Examples: è¿è¥ä¸­å¿ƒ, å®‰ä¿éƒ¨é—¨, ç‰©ä¸šéƒ¨é—¨, ITéƒ¨é—¨
   - Use category: "default"

**STRICT RULES:**
- NO database/cache/queue components (those are technical!)
- NO infrastructure components (K8s, Docker, etc.)
- Focus on BUSINESS VALUE and CAPABILITIES
- Use business-friendly language (Chinese preferred)
"""
            elif arch_type == "technical":
                layer_examples = """
**âš™ï¸ TECHNICAL ARCHITECTURE - Focus on TECHNICAL COMPONENTS:**
CRITICAL: This is a TECHNICAL view showing HOW systems are built!

**Required Layers (use EXACTLY these names):**
1. "presentation" (è¡¨ç°å±‚) - 3-5 UI components
   - Examples: Reactå‰ç«¯, Vueç®¡ç†åå°, ç§»åŠ¨ç«¯App, å°ç¨‹åº
   - Use category: "api"
   - tech_stack: ["React", "TypeScript"], ["Vue", "Element UI"], etc.

2. "application" (åº”ç”¨å±‚) - 6-10 application services
   - Examples: ç”¨æˆ·æœåŠ¡, è®¢å•æœåŠ¡, æ”¯ä»˜æœåŠ¡, é€šçŸ¥æœåŠ¡, è®¤è¯æœåŠ¡
   - Use category: "service"
   - tech_stack: ["Spring Boot", "Java"], ["FastAPI", "Python"], etc.

3. "integration" (é›†æˆå±‚) - 4-6 integration components
   - Examples: API Gateway, æ¶ˆæ¯é˜Ÿåˆ—, ESBæ€»çº¿, æœåŠ¡ç½‘æ ¼
   - Use category: "network"
   - tech_stack: ["Kong"], ["Kafka"], ["Istio"], etc.

4. "data" (æ•°æ®å±‚) - 4-6 data storage systems
   - Examples: MySQLä¸»åº“, Redisç¼“å­˜, MongoDBæ–‡æ¡£åº“, Elasticsearchæœç´¢
   - Use category: "database"
   - tech_stack: ["MySQL 8.0"], ["Redis Cluster"], etc.

5. "infrastructure" (åŸºç¡€è®¾æ–½å±‚) - 3-5 infrastructure components
   - Examples: Kubernetesé›†ç¾¤, Dockerå®¹å™¨, Nginxè´Ÿè½½å‡è¡¡, äº‘æœåŠ¡å™¨
   - Use category: "infrastructure"
   - tech_stack: ["K8s"], ["Docker"], ["Nginx"], etc.

**STRICT RULES:**
- MUST include tech_stack for every item
- Use technical terminology (API, Service, Gateway, etc.)
- Show HOW components interact (include edges!)
- Focus on IMPLEMENTATION details
"""
            elif arch_type == "deployment":
                layer_examples = """
**ğŸš€ DEPLOYMENT ARCHITECTURE - Focus on INFRASTRUCTURE TOPOLOGY:**
CRITICAL: This is a DEPLOYMENT view showing WHERE systems run!

**Required Layers (use EXACTLY these names):**
1. "dmz" (DMZåŒº) - 3-4 edge components
   - Examples: Nginxè´Ÿè½½å‡è¡¡, WAFé˜²ç«å¢™, CDNèŠ‚ç‚¹, SSLç»ˆç»“
   - Use category: "network"
   - tech_stack: ["Nginx", "HAProxy"], ["ModSecurity"], etc.
   - note: Include IP ranges or network segments

2. "app-tier" (åº”ç”¨å±‚) - 5-8 application deployment units
   - Examples: K8s Pod (è®¢å•æœåŠ¡), Dockerå®¹å™¨ (ç”¨æˆ·æœåŠ¡), Tomcatå®ä¾‹
   - Use category: "compute"
   - tech_stack: ["K8s Deployment"], ["Docker Compose"], etc.
   - note: Include replica counts (e.g., "3å‰¯æœ¬")

3. "data-tier" (æ•°æ®å±‚) - 3-5 data storage deployments
   - Examples: MySQLä¸»ä»é›†ç¾¤, Rediså“¨å…µé›†ç¾¤, MinIOå¯¹è±¡å­˜å‚¨
   - Use category: "storage"
   - tech_stack: ["MySQL 8.0 ä¸»ä»"], ["Redis Sentinel"], etc.
   - note: Include HA configuration

4. "monitoring" (ç›‘æ§å±‚) - 3-4 monitoring/logging systems
   - Examples: Prometheusç›‘æ§, Grafanaå¯è§†åŒ–, ELKæ—¥å¿—, Jaegeré“¾è·¯è¿½è¸ª
   - Use category: "platform"
   - tech_stack: ["Prometheus"], ["Grafana"], ["Elasticsearch"], etc.

**STRICT RULES:**
- MUST include deployment details (replicas, HA, network)
- Show PHYSICAL/LOGICAL deployment topology
- Include edges for network connections
- Focus on OPERATIONS and INFRASTRUCTURE
"""
            elif arch_type == "domain":
                layer_examples = """
**ğŸ¯ DOMAIN-DRIVEN ARCHITECTURE - Focus on BOUNDED CONTEXTS:**
CRITICAL: This is a DDD view showing domain boundaries!

**Required Layers (use EXACTLY these names):**
1. "domain-services" (é¢†åŸŸæœåŠ¡å±‚) - 5-8 bounded contexts
   - Examples: è®¢å•åŸŸ, ç”¨æˆ·åŸŸ, æ”¯ä»˜åŸŸ, åº“å­˜åŸŸ, ç‰©æµåŸŸ
   - Use category: "service"
   - note: Include domain responsibilities

2. "shared-kernel" (å…±äº«å†…æ ¸å±‚) - 2-4 shared components
   - Examples: é€šç”¨å·¥å…·ç±», é¢†åŸŸäº‹ä»¶æ€»çº¿, å…±äº«å€¼å¯¹è±¡
   - Use category: "platform"

3. "anti-corruption" (é˜²è…å±‚) - 2-3 integration adapters
   - Examples: å¤–éƒ¨æ”¯ä»˜é€‚é…å™¨, ç¬¬ä¸‰æ–¹ç‰©æµé€‚é…å™¨
   - Use category: "network"

4. "infrastructure" (åŸºç¡€è®¾æ–½å±‚) - 3-4 infrastructure services
   - Examples: æ•°æ®æŒä¹…åŒ–, æ¶ˆæ¯å‘å¸ƒ, ç¼“å­˜æœåŠ¡
   - Use category: "infrastructure"

**STRICT RULES:**
- Use DDD terminology (Bounded Context, Aggregate, etc.)
- Show domain boundaries clearly
- Include edges for domain events
"""
            else:  # layered (default/generic)
                layer_examples = """
**ğŸ¢ LAYERED ARCHITECTURE - Generic multi-tier structure:**

**Required Layers (use EXACTLY these names):**
1. "frontend" (å‰ç«¯å±‚) - 2-4 client applications
2. "backend" (åç«¯å±‚) - 4-6 backend services
3. "middleware" (ä¸­é—´ä»¶å±‚) - 3-5 middleware components
4. "data" (æ•°æ®å±‚) - 3-4 data storage systems
5. "infrastructure" (åŸºç¡€è®¾æ–½å±‚) - 2-3 infrastructure components

**RULES:**
- Generic architecture, suitable for most systems
- Balance between business and technical views
"""

            # Edge generation guidance
            edge_guidance = ""
            if template.get("show_edges", False):
                edge_guidance = """
**EDGE/CONNECTION RULES:**
- Include "edges" array to show dependencies/data flow
- Each edge: {{"source": "layer-item-id", "target": "layer-item-id", "label": "connection type"}}
- Example: {{"source": "application-0", "target": "integration-0", "label": "APIè°ƒç”¨"}}
- Keep edge labels concise (APIè°ƒç”¨, æ•°æ®æµ, ç½‘ç»œè¿æ¥, etc.)
"""
            else:
                edge_guidance = """
**EDGE RULE:** Do NOT include "edges" array - this architecture type focuses on layer organization.
"""

            return f"""You are a professional systems architect. Generate a {template['name']} ({template['name_en']}) with clear hierarchy and organization.

**ARCHITECTURE TYPE:** {template['name']}
**DESCRIPTION:** {template['description']}

**CRITICAL OUTPUT FORMAT:**
1. Return ONLY valid JSON (no markdown code blocks)
2. Structure:
   {{
     "layers": [
       {{
         "name": "layer-name",
         "layout": {{ "columns": 4-6 }},
         "items": [
           {{"label": "Component Name", "tech_stack": ["Technology"], "note": "Description", "category": "service"}}
         ]
       }}
     ],
     "edges": [...]  // Only if showing dependencies
   }}

{layer_examples}

3. **GRID LAYOUT SUPPORT:**
   - Each layer can specify "layout": {{ "columns": N }}
   - Default columns: {template.get('default_columns', 4)}
   - For layers with many items (10+), use more columns (5-6)
   - For simple layers (< 5 items), use fewer columns (3-4)

4. **Item Format:**
   - "label": Component/service name (Chinese if user input is Chinese)
   - "tech_stack": Array of technologies used (e.g., ["React", "Next.js"])
   - "note": Brief description or tech stack summary
   - "category": Optional category for icon selection ("service", "database", "api", "platform", etc.)

5. **SMART CARD DISTRIBUTION:**
   - Capability/service layers: 6-12 items across 4-6 columns
   - Application layer: 5-10 items across 3-5 columns
   - Integration layer: 3-6 items across 3-4 columns
   - Data layer: 3-5 items across 3-4 columns
   - Automatically wrap items into multiple rows

{edge_guidance}

**EXAMPLE OUTPUT (Smart Park Business Architecture):**
{{
  "layers": [
    {{
      "name": "capability",
      "layout": {{ "columns": 6 }},
      "items": [
        {{"label": "è®¿å®¢ç®¡ç†", "category": "service", "note": "è®¿å®¢é¢„çº¦ä¸ç™»è®°"}},
        {{"label": "è½¦è¾†ç®¡ç†", "category": "service", "note": "è½¦è¾†è¯†åˆ«ä¸åœè½¦"}},
        {{"label": "å®‰é˜²ç›‘æ§", "category": "service", "note": "è§†é¢‘ç›‘æ§ä¸é¢„è­¦"}},
        {{"label": "èƒ½æºç®¡ç†", "category": "service", "note": "èƒ½è€—åˆ†æä¸ä¼˜åŒ–"}},
        {{"label": "ç‰©ä¸šæœåŠ¡", "category": "service", "note": "å·¥å•ä¸æŠ•è¯‰å¤„ç†"}},
        {{"label": "æ™ºèƒ½æ¥¼å®‡", "category": "service", "note": "æ¥¼å®‡è‡ªæ§ä¸è°ƒèŠ‚"}},
        {{"label": "ç¯å¢ƒç›‘æµ‹", "category": "service", "note": "ç©ºæ°”è´¨é‡ä¸æ¸©æ¹¿åº¦"}},
        {{"label": "èµ„äº§ç®¡ç†", "category": "service", "note": "èµ„äº§ç›˜ç‚¹ä¸è¿½è¸ª"}},
        {{"label": "åº”æ€¥æŒ‡æŒ¥", "category": "service", "note": "åº”æ€¥å“åº”ä¸è°ƒåº¦"}},
        {{"label": "æ•°æ®åˆ†æ", "category": "platform", "note": "æ•°æ®å¯è§†åŒ–ä¸æŠ¥è¡¨"}},
        {{"label": "ç»Ÿä¸€è®¤è¯", "category": "platform", "note": "å•ç‚¹ç™»å½•ä¸æƒé™"}},
        {{"label": "æ¶ˆæ¯é€šçŸ¥", "category": "platform", "note": "æ¶ˆæ¯æ¨é€ä¸æé†’"}}
      ]
    }},
    {{
      "name": "application",
      "layout": {{ "columns": 5 }},
      "items": [
        {{"label": "è®¿å®¢é¢„çº¦ç³»ç»Ÿ", "tech_stack": ["Vue", "Spring Boot"], "note": "è®¿å®¢é¢„çº¦ä¸å®¡æ‰¹"}},
        {{"label": "è½¦è¾†è¯†åˆ«ç³»ç»Ÿ", "tech_stack": ["TensorFlow", "FastAPI"], "note": "è½¦ç‰Œè¯†åˆ«ä¸æŠ“æ‹"}},
        {{"label": "è§†é¢‘ç›‘æ§å¹³å°", "tech_stack": ["WebRTC", "Node.js"], "note": "è§†é¢‘æµå¤„ç†"}},
        {{"label": "èƒ½è€—åˆ†æå¹³å°", "tech_stack": ["Grafana", "InfluxDB"], "note": "èƒ½è€—æ•°æ®åˆ†æ"}},
        {{"label": "ç‰©ä¸šå·¥å•ç³»ç»Ÿ", "tech_stack": ["React", "Django"], "note": "å·¥å•æµè½¬å¤„ç†"}}
      ]
    }},
    {{
      "name": "integration",
      "layout": {{ "columns": 4 }},
      "items": [
        {{"label": "API Gateway", "tech_stack": ["Kong"], "note": "ç»Ÿä¸€ç½‘å…³"}},
        {{"label": "ESBæ€»çº¿", "tech_stack": ["Kafka"], "note": "æ¶ˆæ¯æ€»çº¿"}},
        {{"label": "IoTå¹³å°", "tech_stack": ["EMQ X"], "note": "è®¾å¤‡æ¥å…¥"}},
        {{"label": "æ•°æ®äº¤æ¢", "tech_stack": ["DataX"], "note": "æ•°æ®åŒæ­¥"}}
      ]
    }},
    {{
      "name": "data",
      "layout": {{ "columns": 5 }},
      "items": [
        {{"label": "ä¸šåŠ¡æ•°æ®åº“", "tech_stack": ["PostgreSQL"], "note": "ä¸»æ•°æ®åº“"}},
        {{"label": "æ—¶åºæ•°æ®åº“", "tech_stack": ["InfluxDB"], "note": "IoTæ•°æ®"}},
        {{"label": "å›¾æ•°æ®åº“", "tech_stack": ["Neo4j"], "note": "å…³ç³»å›¾è°±"}},
        {{"label": "ç¼“å­˜å±‚", "tech_stack": ["Redis Cluster"], "note": "åˆ†å¸ƒå¼ç¼“å­˜"}},
        {{"label": "æ•°æ®æ¹–", "tech_stack": ["MinIO"], "note": "å¯¹è±¡å­˜å‚¨"}}
      ]
    }}
  ]
}}

{template_context}
**User Request:** "{request.user_input}"

Generate {template['name']} with optimal layout, clear layer organization, and appropriate item distribution.
"""

        system_prompt = f"""You are a professional flowchart generation expert. Create beautiful, well-organized flowcharts with optimal layout.

**AVAILABLE NODE TYPES:**
Basic Flow (for general processes):
- start: Start point (use shape="start-event" for BPMN style circle)
- end: End point (use shape="end-event" for BPMN style circle)
- process: Process/Task (use shape="task" for modern card style, or "rectangle" for simple box)
- decision: Decision/Gateway (use shape="diamond" for yes/no branches)
- data: Data Input/Output (use shape="parallelogram")
- subprocess: Sub-process (use shape="rounded-rectangle")

Technical Nodes (ONLY for technical architecture):
- api, service, database, cache, queue, storage, client, gateway

**LAYOUT ALGORITHM - CRITICAL (BALANCED GRID):**
1. **Main spine**: Start near center (x=0, y=100). Keep the core flow mostly top-to-bottom.
2. **Horizontal spread**: Use a 3-5 column grid with x positions spaced ~220-280px (e.g., -420, -200, 0, 220, 440). Do NOT stack everything in one column or only on the left.
3. **Decision branches**:
   - Place branch nodes at the SAME y-level as the decision.
   - Mirror positions left/right (e.g., x=-240 for "No", x=+240 for "Yes") to keep symmetry.
   - Rejoin branches after 1-2 steps at a centered node.
4. **Parallel processes**: Keep siblings aligned horizontally on the same y. Use even spacing (Â±240/Â±480 from center) so the layout feels balanced.
5. **Long flows**: After every 3-4 steps, gently shift the spine to an adjacent column (x=+200 or -200) to avoid a single vertical line while keeping flow mostly downward.
6. **Edge directions**:
   - Sequential: Vertical (top to bottom)
   - Branches: Diagonal or horizontal
   - Avoid all edges exiting from the same side; balance entry/exit points.

**LAYOUT EXAMPLE (Decision Flow):**
{{
  "nodes": [
    {{"id": "start", "type": "default", "position": {{"x": 400, "y": 100}},
      "data": {{"label": "å¼€å§‹", "shape": "start-event", "color": "#16a34a"}}}},
    {{"id": "step1", "type": "default", "position": {{"x": 400, "y": 280}},
      "data": {{"label": "æäº¤ç”³è¯·", "shape": "task", "color": "#2563eb"}}}},
    {{"id": "decision1", "type": "gateway", "position": {{"x": 400, "y": 460}},
      "data": {{"label": "å®¡æ‰¹é€šè¿‡?", "shape": "diamond"}}}},
    {{"id": "yes-branch", "type": "default", "position": {{"x": 400, "y": 640}},
      "data": {{"label": "å‘æ”¾é€šçŸ¥", "shape": "task", "color": "#2563eb"}}}},
    {{"id": "no-branch", "type": "default", "position": {{"x": 50, "y": 640}},
      "data": {{"label": "é©³å›å¹¶è¯´æ˜åŸå› ", "shape": "task", "color": "#dc2626"}}}},
    {{"id": "end", "type": "default", "position": {{"x": 400, "y": 820}},
      "data": {{"label": "ç»“æŸ", "shape": "end-event", "color": "#dc2626"}}}}
  ],
  "edges": [
    {{"id": "e1", "source": "start", "target": "step1"}},
    {{"id": "e2", "source": "step1", "target": "decision1"}},
    {{"id": "e3", "source": "decision1", "target": "yes-branch", "label": "æ˜¯"}},
    {{"id": "e4", "source": "decision1", "target": "no-branch", "label": "å¦"}},
    {{"id": "e5", "source": "yes-branch", "target": "end"}},
    {{"id": "e6", "source": "no-branch", "target": "end"}}
  ]
}}

**STYLING RULES:**
1. Use BPMN shapes for clean look:
   - start-event: Green (#16a34a)
   - end-event: Red (#dc2626)
   - task: Blue (#2563eb)
   - gateway/decision: No color override (default gray)
2. DO NOT use iconType field - system provides default icons
3. Label text should be concise (5-15 Chinese chars, 3-8 English words)
4. For loops: Position loop-back nodes to the right (+350px)

**GENERATION RULES:**
1. Analyze user input to identify:
   - Decision points (questions, conditions, branches)
   - Sequential steps
   - Parallel processes
   - Loop logic
2. For simple flows (5-8 nodes):
   - Linear top-to-bottom with 1-2 decisions
3. For complex flows (10-15 nodes):
   - Multiple decision branches
   - Use horizontal space for clarity
4. Avoid cluttered layouts:
   - Max 3 parallel branches
   - Clear visual separation between branches

**OUTPUT FORMAT:**
{{
  "nodes": [...],  // Array of node objects with position/type/data
  "edges": [...],  // Array of edge objects with source/target/label
  "mermaid_code": "graph TB\\n..."  // Optional Mermaid syntax
}}

{template_context}

**User Request:** "{request.user_input}"

Generate a well-laid-out flowchart. Focus on clarity and visual balance. Return ONLY valid JSON, no markdown blocks."""
        return system_prompt

    async def _call_ai_text_generation(self, vision_service, prompt: str, provider: str) -> dict:
        """Call AI provider (placeholder)."""
        if provider == "gemini":
            response = await vision_service._analyze_with_gemini_text(prompt)
        elif provider == "openai":
            response = await vision_service._analyze_with_openai_text(prompt)
        elif provider == "claude":
            response = await vision_service._analyze_with_claude_text(prompt)
        elif provider == "siliconflow":
            response = await vision_service._analyze_with_siliconflow_text(prompt)
        else:
            response = await vision_service._analyze_with_custom_text(prompt)
        return response

    def _bpmn_colors(self):
        return {
            "start": "#16a34a",
            "end": "#dc2626",
            "intermediate": "#ca8a04",
            "task": "#2563eb",
        }

    def _safe_json(self, payload: Any) -> dict:
        """Normalize AI payload into dict."""
        if payload is None:
            return {}
        if isinstance(payload, dict):
            return payload
        if isinstance(payload, str):
            # Clean markdown code blocks (```json ... ``` or ``` ... ```)
            cleaned = payload.strip()
            if cleaned.startswith("```"):
                # Remove opening ```json or ```
                lines = cleaned.split("\n")
                if lines[0].startswith("```"):
                    lines = lines[1:]
                # Remove closing ```
                if lines and lines[-1].strip() == "```":
                    lines = lines[:-1]
                cleaned = "\n".join(lines)
            return json.loads(cleaned)
        if hasattr(payload, "model_dump"):  # pydantic models
            return payload.model_dump()
        return json.loads(json.dumps(payload, default=str))

    def _calculate_frame_size(self, items_count: int, columns: int = 4) -> dict:
        """
        Calculate dynamic frame size based on number of items and columns.

        Args:
            items_count: Number of items in the layer
            columns: Number of columns in grid layout (default: 4)

        Returns:
            dict with 'width' and 'height' in pixels
        """
        item_width = 240  # Width of each component card
        item_height = 100  # Height of each component card
        padding = 60  # Frame padding
        gap = 20  # Gap between items
        header_height = 40  # Layer header height

        # Calculate actual columns (don't exceed items count)
        actual_columns = min(items_count, columns) if items_count > 0 else columns

        # Calculate rows needed
        rows = (items_count + columns - 1) // columns if items_count > 0 else 1

        # Calculate dimensions
        width = actual_columns * item_width + (actual_columns - 1) * gap + padding * 2
        height = rows * item_height + (rows - 1) * gap + padding * 2 + header_height

        return {
            "width": max(width, 800),  # Minimum width for aesthetics
            "height": max(height, 150),  # Minimum height
        }

    def _normalize_architecture_graph(self, ai_data: dict, architecture_type: str = "layered"):
        """
        Normalize architecture JSON (layers/items) into nodes with LayerFrame backgrounds.
        Supports dynamic sizing and grid layout.

        Args:
            ai_data: AI-generated architecture data
            architecture_type: Type of architecture (layered, business, technical, deployment, domain)

        Returns:
            Tuple of (nodes, edges, mermaid_code)
        """
        try:
            layers = (
                ai_data.get("layers")
                or ai_data.get("sections")
                or ai_data.get("architecture")
                or ai_data.get("groups")
                or []
            )
            # Extract edges if provided (for technical/deployment architectures)
            ai_edges = ai_data.get("edges", [])
        except Exception:
            return [], [], ""

        nodes = []
        edges = []

        # Enhanced layer colors with more types
        layer_colors = {
            # Layered architecture
            "frontend": "#f59e0b",      # Orange
            "backend": "#22c55e",       # Green
            "middleware": "#6366f1",    # Indigo
            "data": "#a855f7",          # Purple
            "infrastructure": "#0ea5e9", # Sky blue
            "observability": "#14b8a6", # Teal
            # Business architecture
            "capability": "#f59e0b",    # Orange
            "service": "#22c55e",       # Green
            "process": "#6366f1",       # Indigo
            "organization": "#a855f7",  # Purple
            # Technical architecture
            "presentation": "#f59e0b",  # Orange
            "application": "#22c55e",   # Green
            "integration": "#6366f1",   # Indigo
            # Deployment architecture
            "dmz": "#ef4444",           # Red
            "app-tier": "#22c55e",      # Green
            "data-tier": "#a855f7",     # Purple
            "monitoring": "#14b8a6",    # Teal
            # Domain architecture
            "domain-services": "#22c55e",     # Green
            "shared-kernel": "#6366f1",       # Indigo
            "anti-corruption": "#f59e0b",     # Orange
        }

        # Get template configuration
        template = ARCHITECTURE_TEMPLATES.get(architecture_type, ARCHITECTURE_TEMPLATES["layered"])
        default_columns = template.get("default_columns", 4)

        # Configuration for layout
        frame_padding_x = 60
        frame_padding_y = 100
        layer_spacing_y = 200
        item_width = 240
        item_height = 100
        padding = 60
        gap = 20
        header_height = 40

        if isinstance(layers, dict):
            layers = [{"name": k, "items": v} for k, v in layers.items()]
        elif not isinstance(layers, list):
            return [], [], ""

        # Track cumulative Y position
        current_y = frame_padding_y

        # Generate nodes with LayerFrame backgrounds
        for layer_idx, layer in enumerate(layers):
            layer_name = layer.get("name") if isinstance(layer, dict) else f"layer-{layer_idx}"
            items = layer.get("items", []) if isinstance(layer, dict) else []
            color = layer_colors.get(layer_name.lower(), "#64748b")

            # Get layout configuration for this layer
            layer_layout = layer.get("layout", {}) if isinstance(layer, dict) else {}
            columns = layer_layout.get("columns", default_columns)

            # Calculate dynamic frame size based on items count
            frame_size = self._calculate_frame_size(len(items), columns)

            # Add LayerFrame background node with dynamic sizing
            layer_frame_id = f"{layer_name}-frame"
            nodes.append({
                "id": layer_frame_id,
                "type": "layerFrame",
                "position": {"x": frame_padding_x, "y": current_y},
                "data": {
                    "label": layer_name.capitalize(),
                    "color": color,
                    "width": frame_size["width"],
                    "height": frame_size["height"],
                    "layout": "grid",  # NEW: Indicate grid layout mode
                    "columns": columns,  # NEW: Number of columns for grid
                    "itemsCount": len(items),  # NEW: Track item count
                },
                "draggable": False,
                # CRITICAL: Set style to define the draggable area for child nodes
                "style": {
                    "width": frame_size["width"],
                    "height": frame_size["height"],
                },
            })

            # Position component nodes in grid layout RELATIVE to parent
            for item_idx, item in enumerate(items):
                if isinstance(item, dict):
                    label = item.get("label") or item.get("name") or f"{layer_name}-{item_idx}"
                    tech_stack = item.get("tech_stack", []) or []
                    note = item.get("note") or (", ".join(tech_stack) if tech_stack else "")
                    category = item.get("category", "service")  # NEW: Category for icons
                else:
                    label = str(item)
                    note = ""
                    tech_stack = []
                    category = "service"

                # Calculate grid position
                row = item_idx // columns
                col = item_idx % columns

                # Calculate RELATIVE position (relative to parent LayerFrame)
                # Start from padding, not absolute coordinates
                item_x_relative = padding + col * (item_width + gap)
                item_y_relative = header_height + padding + row * (item_height + gap)

                nodes.append({
                    "id": f"{layer_name}-{item_idx}",
                    "type": "frame",
                    "position": {"x": item_x_relative, "y": item_y_relative},  # RELATIVE position
                    "parentNode": layer_frame_id,  # CRITICAL: Set parent relationship
                    "extent": "parent",  # CRITICAL: Constrain dragging within parent
                    "data": {
                        "label": label,
                        "shape": "task",
                        "color": color,
                        "layer": layer_name,
                        "note": note,
                        "layerColor": color,
                        "tech_stack": tech_stack if isinstance(tech_stack, list) else [],
                        "category": category,  # NEW: For visual enhancements
                    },
                })

            # Update current_y for next layer (with spacing)
            current_y += frame_size["height"] + layer_spacing_y

        # Process edges if provided (for technical/deployment architectures)
        for edge_idx, edge_data in enumerate(ai_edges):
            if isinstance(edge_data, dict):
                source = edge_data.get("source")
                target = edge_data.get("target")
                if source and target:
                    edges.append({
                        "id": edge_data.get("id") or f"e-{edge_idx}",
                        "source": source,
                        "target": target,
                        "label": edge_data.get("label", ""),
                        "type": edge_data.get("type", "dependency"),
                    })

        # Generate mermaid code
        mermaid_lines = [f"# {template['name']} ({template['name_en']})"]
        for layer in layers:
            lname = layer.get("name") if isinstance(layer, dict) else str(layer)
            mermaid_lines.append(f"## {lname.capitalize()}")
            items = layer.get("items", []) if isinstance(layer, dict) else []
            for item in items:
                if isinstance(item, dict):
                    label = item.get("label") or item.get("name") or "component"
                    tech_stack = item.get("tech_stack", []) or []
                    note = item.get("note") or ", ".join(tech_stack)
                    mermaid_lines.append(f"- **{label}**: {note}")
                else:
                    mermaid_lines.append(f"- {item}")
        mermaid_code = "\n".join(mermaid_lines)

        return nodes, edges, mermaid_code

    def _ensure_positions(self, nodes: List[dict]) -> List[dict]:
        """Guarantee each node has position/data/type for React Flow."""
        cleaned = []
        start_x, start_y, step_x, step_y = 120, 120, 260, 180
        for idx, node in enumerate(nodes):
            n = node.model_dump() if hasattr(node, "model_dump") else dict(node)
            label_value = n.pop("label", None)
            if "position" not in n or not isinstance(n.get("position"), dict):
                # Accept legacy x/y fields
                x = n.pop("x", None)
                y = n.pop("y", None)
                col, row = idx % 4, idx // 4
                n["position"] = {
                    "x": x if isinstance(x, (int, float)) else start_x + col * step_x,
                    "y": y if isinstance(y, (int, float)) else start_y + row * step_y + (50 if col % 2 else 0),
                }
            else:
                if "x" not in n["position"]:
                    n["position"]["x"] = start_x + (idx % 4) * step_x
                if "y" not in n["position"]:
                    n["position"]["y"] = start_y + (idx // 4) * step_y

            n.setdefault("type", "default")
            if "data" not in n or not isinstance(n["data"], dict):
                n["data"] = {}
            if label_value is not None:
                n["data"].setdefault("label", label_value)
            n["data"].setdefault("label", n.get("id", "node"))
            cleaned.append(n)
        return cleaned

    def _ensure_edges(self, edges: List[dict]) -> List[dict]:
        """Ensure edges have ids and required fields."""
        cleaned = []
        for idx, edge in enumerate(edges):
            e = edge.model_dump() if hasattr(edge, "model_dump") else dict(edge)
            if not e.get("source") or not e.get("target"):
                continue
            e.setdefault("id", e.get("id") or f"e{idx}")
            cleaned.append(e)
        return cleaned

    def _normalize_ai_graph(self, ai_data: dict) -> Tuple[List[dict], List[dict], str]:
        """Normalize AI response into nodes/edges/mermaid_code."""
        nodes = ai_data.get("nodes") or []
        edges = ai_data.get("edges") or []
        mermaid_code = (
            ai_data.get("mermaid_code")
            or ai_data.get("mermaid")
            or ai_data.get("mermaidCode")
            or ""
        )

        # If only mermaid is returned, parse it
        if (not nodes) and mermaid_code:
            try:
                parsed_nodes, parsed_edges = parse_mermaid_to_graph(mermaid_code)
                nodes = [n.model_dump() if hasattr(n, "model_dump") else dict(n) for n in parsed_nodes]
                edges = [e.model_dump() if hasattr(e, "model_dump") else dict(e) for e in parsed_edges]
            except Exception as e:
                logger.warning(f"Failed to parse mermaid from AI response: {e}")

        nodes = self._ensure_positions(nodes)
        edges = self._ensure_edges(edges)

        # Auto-wire edges sequentially if missing but multiple nodes exist
        if not edges and len(nodes) > 1:
            sorted_nodes = sorted(nodes, key=lambda n: (n["position"]["x"], n["position"]["y"]))
            auto_edges = []
            for idx in range(len(sorted_nodes) - 1):
                src = sorted_nodes[idx]["id"]
                tgt = sorted_nodes[idx + 1]["id"]
                auto_edges.append({"id": f"e{idx}", "source": src, "target": tgt, "label": None})
            edges = self._ensure_edges(auto_edges)

        if not mermaid_code and nodes:
            try:
                mermaid_code = graph_to_mermaid(
                    [Node(**n) for n in nodes],
                    [Edge(**e) for e in edges],
                )
            except Exception as e:
                logger.warning(f"Failed to rebuild mermaid code: {e}")
                mermaid_code = ""

        return nodes, edges, mermaid_code

    def _mock_microservice_architecture(self):
        c = self._bpmn_colors()
        nodes = [
            {"id": "start-1", "type": "default", "position": {"x": 50, "y": 200},
             "data": {"label": "å¼€å§‹", "shape": "start-event", "iconType": "play-circle", "color": c["start"]}},
            {"id": "client-1", "type": "client", "position": {"x": 200, "y": 200},
             "data": {"label": "Web Client"}},
            {"id": "gateway-1", "type": "gateway", "position": {"x": 500, "y": 200},
             "data": {"label": "API Gateway", "shape": "diamond"}},
            {"id": "gateway-2", "type": "gateway", "position": {"x": 800, "y": 100},
             "data": {"label": "è®¤è¯é€šè¿‡?", "shape": "diamond"}},
            {"id": "api-1", "type": "api", "position": {"x": 1100, "y": 100},
             "data": {"label": "Auth Service"}},
            {"id": "cache-1", "type": "cache", "position": {"x": 800, "y": 300},
             "data": {"label": "Redis Cache"}},
            {"id": "service-1", "type": "service", "position": {"x": 1100, "y": 300},
             "data": {"label": "Order Service", "shape": "task", "iconType": "box", "color": c["task"]}},
            {"id": "queue-1", "type": "queue", "position": {"x": 1400, "y": 200},
             "data": {"label": "RabbitMQ"}},
            {"id": "service-2", "type": "service", "position": {"x": 1700, "y": 200},
             "data": {"label": "Inventory Service", "shape": "task", "iconType": "box", "color": c["task"]}},
            {"id": "database-1", "type": "database", "position": {"x": 1400, "y": 400},
             "data": {"label": "MySQL"}},
            {"id": "storage-1", "type": "storage", "position": {"x": 1700, "y": 400},
             "data": {"label": "OSS Storage"}},
            {"id": "end-1", "type": "default", "position": {"x": 2000, "y": 200},
             "data": {"label": "ç»“æŸ", "shape": "end-event", "iconType": "stop-circle", "color": c["end"]}},
        ]
        edges = [
            {"id": "e0", "source": "start-1", "target": "client-1", "label": "ç”¨æˆ·è¯·æ±‚"},
            {"id": "e1", "source": "client-1", "target": "gateway-1", "label": "HTTPS Request"},
            {"id": "e2", "source": "gateway-1", "target": "gateway-2", "label": "éªŒè¯Token"},
            {"id": "e3", "source": "gateway-2", "target": "api-1", "label": "æ˜¯"},
            {"id": "e4", "source": "gateway-2", "target": "cache-1", "label": "å¦"},
            {"id": "e5", "source": "cache-1", "target": "service-1", "label": "Cache Miss"},
            {"id": "e6", "source": "service-1", "target": "queue-1", "label": "å¼‚æ­¥è®¢å•"},
            {"id": "e7", "source": "queue-1", "target": "service-2", "label": "æ¶ˆè´¹æ¶ˆæ¯"},
            {"id": "e8", "source": "service-1", "target": "database-1", "label": "æŸ¥è¯¢è®¢å•"},
            {"id": "e9", "source": "service-2", "target": "database-1", "label": "æ›´æ–°åº“å­˜"},
            {"id": "e10", "source": "service-2", "target": "storage-1", "label": "ä¸Šä¼ å‘è´§å•"},
            {"id": "e11", "source": "service-2", "target": "end-1", "label": "ç»“æŸ"},
        ]
        mermaid_code = """graph LR
    start-1(("å¼€å§‹"))
    client-1["Web Client"]
    gateway-1{"API Gateway"}
    gateway-2{"è®¤è¯é€šè¿‡?"}
    api-1["Auth Service"]
    cache-1["Redis Cache"]
    service-1["Order Service"]
    queue-1["RabbitMQ"]
    service-2["Inventory Service"]
    database-1["MySQL"]
    storage-1["OSS Storage"]
    end-1(("ç»“æŸ"))

    start-1 -->|ç”¨æˆ·è¯·æ±‚| client-1
    client-1 -->|HTTPS Request| gateway-1
    gateway-1 -->|éªŒè¯Token| gateway-2
    gateway-2 -->|æ˜¯| api-1
    gateway-2 -->|å¦| cache-1
    cache-1 -->|Cache Miss| service-1
    service-1 -->|å¼‚æ­¥è®¢å•| queue-1
    queue-1 -->|æ¶ˆè´¹æ¶ˆæ¯| service-2
    service-1 -->|æŸ¥è¯¢è®¢å•| database-1
    service-2 -->|æ›´æ–°åº“å­˜| database-1
    service-2 -->|ä¸Šä¼ å‘è´§å•| storage-1
    service-2 -->|ç»“æŸ| end-1"""
        return {"nodes": nodes, "edges": edges, "mermaid_code": mermaid_code}

    def _mock_high_concurrency(self):
        c = self._bpmn_colors()
        nodes = [
            {"id": "start-1", "type": "default", "position": {"x": -150, "y": 200},
             "data": {"label": "å¼€å§‹", "shape": "start-event", "iconType": "play-circle", "color": c["start"]}},
            {"id": "client-1", "type": "client", "position": {"x": 100, "y": 200}, "data": {"label": "Mobile App"}},
            {"id": "gateway-1", "type": "gateway", "position": {"x": 400, "y": 200},
             "data": {"label": "API Gateway\n(é™æµ 10000 QPS)", "shape": "diamond"}},
            {"id": "cache-1", "type": "cache", "position": {"x": 700, "y": 200},
             "data": {"label": "Redis\n(ç¼“å­˜å‰ç½®)"}},
            {"id": "gateway-2", "type": "gateway", "position": {"x": 1000, "y": 200},
             "data": {"label": "ç¼“å­˜å‘½ä¸­?", "shape": "diamond"}},
            {"id": "queue-1", "type": "queue", "position": {"x": 1300, "y": 100},
             "data": {"label": "Kafka Queue\n(å‰Šå³°)" }},
            {"id": "service-1", "type": "service", "position": {"x": 1600, "y": 100},
             "data": {"label": "Order Service", "shape": "task", "iconType": "box", "color": c["task"]}},
            {"id": "database-1", "type": "database", "position": {"x": 1900, "y": 100},
             "data": {"label": "MySQL\n(è®¢å•è¡¨)"}},
            {"id": "storage-1", "type": "storage", "position": {"x": 1900, "y": 300},
             "data": {"label": "OSS\n(è®¢å•å‡­è¯)"}},
            {"id": "client-2", "type": "client", "position": {"x": 1300, "y": 300},
             "data": {"label": "è¿”å›å¤±è´¥"}},
            {"id": "end-1", "type": "default", "position": {"x": 2200, "y": 200},
             "data": {"label": "ç»“æŸ", "shape": "end-event", "iconType": "stop-circle", "color": c["end"]}},
        ]
        edges = [
            {"id": "e0", "source": "start-1", "target": "client-1", "label": "å…¥å£"},
            {"id": "e1", "source": "client-1", "target": "gateway-1", "label": "é«˜å¹¶å‘è¯·æ±‚"},
            {"id": "e2", "source": "gateway-1", "target": "cache-1", "label": "é™æµé€šè¿‡"},
            {"id": "e3", "source": "cache-1", "target": "gateway-2", "label": "æ£€æŸ¥ç¼“å­˜"},
            {"id": "e4", "source": "gateway-2", "target": "queue-1", "label": "æ˜¯"},
            {"id": "e5", "source": "gateway-2", "target": "client-2", "label": "å¦"},
            {"id": "e6", "source": "queue-1", "target": "service-1", "label": "æ¶ˆè´¹"},
            {"id": "e7", "source": "service-1", "target": "database-1", "label": "åˆ›å»ºè®¢å•"},
            {"id": "e8", "source": "service-1", "target": "storage-1", "label": "å­˜å‚¨å‡­è¯"},
            {"id": "e9", "source": "service-1", "target": "end-1", "label": "ç»“æŸ"},
        ]
        mermaid_code = """graph LR
    start-1(("å¼€å§‹"))
    client-1["Mobile App"]
    gateway-1{"API Gateway<br/>(é™æµ 10000 QPS)"}
    cache-1["Redis<br/>(ç¼“å­˜å‰ç½®)"]
    gateway-2{"ç¼“å­˜å‘½ä¸­?"}
    queue-1["Kafka Queue<br/>(å‰Šå³°)"]
    service-1["Order Service"]
    database-1["MySQL<br/>(è®¢å•è¡¨)"]
    storage-1["OSS<br/>(è®¢å•å‡­è¯)"]
    client-2["è¿”å›å¤±è´¥"]
    end-1(("ç»“æŸ"))

    start-1 -->|å…¥å£| client-1
    client-1 -->|é«˜å¹¶å‘è¯·æ±‚| gateway-1
    gateway-1 -->|é™æµé€šè¿‡| cache-1
    cache-1 -->|æ£€æŸ¥ç¼“å­˜| gateway-2
    gateway-2 -->|æ˜¯| queue-1
    gateway-2 -->|å¦| client-2
    queue-1 -->|æ¶ˆè´¹| service-1
    service-1 -->|åˆ›å»ºè®¢å•| database-1
    service-1 -->|å­˜å‚¨å‡­è¯| storage-1
    service-1 -->|ç»“æŸ| end-1"""
        return {"nodes": nodes, "edges": edges, "mermaid_code": mermaid_code}

    def _mock_oom_investigation(self):
        c = self._bpmn_colors()
        nodes = [
            {"id": "start-1", "type": "default", "position": {"x": 250, "y": 50},
             "data": {"label": "æ£€æµ‹åˆ°æœåŠ¡å™¨ OOM å‘Šè­¦", "shape": "start-event", "iconType": "alert-circle", "color": c["start"]}},
            {"id": "check-1", "type": "default", "position": {"x": 250, "y": 180},
             "data": {"label": "æŸ¥çœ‹ JVM å †å†…å­˜ä½¿ç”¨ç‡", "shape": "task", "iconType": "box", "color": c["task"]}},
            {"id": "decision-1", "type": "gateway", "position": {"x": 250, "y": 310},
             "data": {"label": "å †å†…å­˜ > 90%?", "shape": "diamond"}},
            {"id": "step-heap-yes", "type": "default", "position": {"x": 100, "y": 440},
             "data": {"label": "ç”Ÿæˆ heap dump", "shape": "task", "iconType": "box", "color": c["task"]}},
            {"id": "step-heap-no", "type": "default", "position": {"x": 400, "y": 440},
             "data": {"label": "æ£€æŸ¥ç›´æ¥å†…å­˜/å…ƒç©ºé—´", "shape": "task", "iconType": "box", "color": c["task"]}},
            {"id": "step-analyze", "type": "default", "position": {"x": 100, "y": 570},
             "data": {"label": "ç”¨ MAT åˆ†æ heap dump", "shape": "task", "iconType": "box", "color": c["task"]}},
            {"id": "step-threads", "type": "default", "position": {"x": 400, "y": 570},
             "data": {"label": "åˆ†æçº¿ç¨‹æ ˆå’Œ GC æ—¥å¿—", "shape": "task", "iconType": "box", "color": c["task"]}},
            {"id": "decision-2", "type": "gateway", "position": {"x": 100, "y": 700},
             "data": {"label": "å‘ç°å†…å­˜æ³„æ¼?", "shape": "diamond"}},
            {"id": "step-leak-yes", "type": "default", "position": {"x": 100, "y": 830},
             "data": {"label": "ä¿®å¤æ³„æ¼ä»£ç å¹¶å›å½’", "shape": "task", "iconType": "box", "color": c["task"]}},
            {"id": "step-leak-no", "type": "default", "position": {"x": 250, "y": 830},
             "data": {"label": "ä¼˜åŒ–å†…å­˜é…ç½®/é™æµ", "shape": "task", "iconType": "box", "color": c["task"]}},
            {"id": "end-1", "type": "default", "position": {"x": 175, "y": 960},
             "data": {"label": "é‡å¯æœåŠ¡å¹¶ç›‘æ§", "shape": "end-event", "iconType": "stop-circle", "color": c["end"]}},
        ]
        edges = [
            {"id": "e1", "source": "start-1", "target": "check-1"},
            {"id": "e2", "source": "check-1", "target": "decision-1"},
            {"id": "e3", "source": "decision-1", "target": "step-heap-yes", "label": "æ˜¯"},
            {"id": "e4", "source": "decision-1", "target": "step-heap-no", "label": "å¦"},
            {"id": "e5", "source": "step-heap-yes", "target": "step-analyze"},
            {"id": "e6", "source": "step-heap-no", "target": "step-threads"},
            {"id": "e7", "source": "step-analyze", "target": "decision-2"},
            {"id": "e8", "source": "decision-2", "target": "step-leak-yes", "label": "æ˜¯"},
            {"id": "e9", "source": "decision-2", "target": "step-leak-no", "label": "å¦"},
            {"id": "e10", "source": "step-leak-yes", "target": "end-1"},
            {"id": "e11", "source": "step-leak-no", "target": "end-1"},
            {"id": "e12", "source": "step-threads", "target": "step-leak-no"},
        ]
        mermaid_code = """graph TD
    start-1(("æ£€æµ‹åˆ°æœåŠ¡å™¨ OOM å‘Šè­¦"))
    check-1["æŸ¥çœ‹ JVM å †å†…å­˜ä½¿ç”¨ç‡"]
    decision-1{"å †å†…å­˜ > 90%?"}
    step-heap-yes["ç”Ÿæˆ heap dump"]
    step-heap-no["æ£€æŸ¥ç›´æ¥å†…å­˜/å…ƒç©ºé—´"]
    step-analyze["ç”¨ MAT åˆ†æ heap dump"]
    step-threads["åˆ†æçº¿ç¨‹æ ˆå’Œ GC æ—¥å¿—"]
    decision-2{"å‘ç°å†…å­˜æ³„æ¼?"}
    step-leak-yes["ä¿®å¤æ³„æ¼ä»£ç å¹¶å›å½’"]
    step-leak-no["ä¼˜åŒ–å†…å­˜é…ç½®/é™æµ"]
    end-1(("é‡å¯æœåŠ¡å¹¶ç›‘æ§"))

    start-1 --> check-1
    check-1 --> decision-1
    decision-1 -->|æ˜¯| step-heap-yes
    decision-1 -->|å¦| step-heap-no
    step-heap-yes --> step-analyze
    step-heap-no --> step-threads
    step-analyze --> decision-2
    decision-2 -->|æ˜¯| step-leak-yes
    decision-2 -->|å¦| step-leak-no
    step-leak-yes --> end-1
    step-leak-no --> end-1
        step-threads --> step-leak-no"""
        return {"nodes": nodes, "edges": edges, "mermaid_code": mermaid_code}

    def _mock_architecture_overview(self):
        """Mock layered architecture map with no edges."""
        layers = [
            ("infrastructure", ["VPC/Subnet", "Load Balancer", "Object Storage", "Monitoring"]),
            ("middleware", ["API Gateway", "Kafka", "Redis", "Config Center"]),
            ("backend", ["User Service", "Order Service", "Payment Worker"]),
            ("frontend", ["Web SPA", "Mobile App", "BFF"]),
            ("data", ["MySQL", "ClickHouse", "Data Lake"]),
        ]
        colors = {
            "infrastructure": "#0ea5e9",
            "middleware": "#6366f1",
            "backend": "#22c55e",
            "frontend": "#f59e0b",
            "data": "#a855f7",
        }
        nodes = []
        frame_width = 1100
        frame_height = 180
        for li, (layer, items) in enumerate(layers):
            nodes.append(
                {
                    "id": f"{layer}-frame",
                    "type": "layerFrame",
                    "position": {"x": 60, "y": 100 + li * (frame_height + 20)},
                    "data": {
                        "label": layer.capitalize(),
                        "color": colors.get(layer, "#64748b"),
                        "width": frame_width,
                        "height": frame_height,
                    },
                    "draggable": False,
                }
            )
            for idx, label in enumerate(items):
                layer_tag = layer.capitalize()
                display_label = f"[{layer_tag}] {label}"
                nodes.append(
                    {
                        "id": f"{layer}-{idx}",
                        "type": "frame",
                        "position": {"x": 120 + idx * 240, "y": 140 + li * (frame_height + 20)},
                        "data": {
                            "label": display_label,
                            "shape": "task",
                            "iconType": "box",
                            "color": colors.get(layer, "#64748b"),
                            "layer": layer,
                            "note": layer_tag,
                            "layerColor": colors.get(layer, "#64748b"),
                        },
                    }
                )
        mermaid_lines = ["# Architecture Overview (mock)"]
        for layer, items in layers:
            mermaid_lines.append(f"- {layer}:")
            for label in items:
                mermaid_lines.append(f"  - {label}")
        return {"nodes": nodes, "edges": [], "mermaid_code": "\n".join(mermaid_lines)}

    async def generate_flowchart(
        self,
        request: ChatGenerationRequest,
        provider: str = "gemini",
        api_key: Optional[str] = None,
        base_url: Optional[str] = None,
        model_name: Optional[str] = None,
    ) -> ChatGenerationResponse:
        """Generate flowchart or architecture diagram via AI."""

        logger.info(f"Generating flowchart for input: {request.user_input[:50]}...")
        logger.info(f"Template ID: {request.template_id}")

        try:
            selected_provider = provider or request.provider or "gemini"
            logger.info(f"[CHAT-GEN] === START generate_flowchart ===")
            logger.info(f"[CHAT-GEN] user_input: {request.user_input[:100] if request.user_input else 'None'}...")
            logger.info(f"[CHAT-GEN] template_id: {request.template_id}")
            logger.info(f"[CHAT-GEN] diagram_type from request: {request.diagram_type}")

            # auto-detect architecture mode by template category if diagram_type not explicitly set
            effective_diagram_type = request.diagram_type or "flow"
            if request.template_id:
                tpl = self.get_template(request.template_id)
                if tpl and tpl.category == "architecture":
                    effective_diagram_type = "architecture"

            logger.info(f"[CHAT-GEN] Effective diagram type: {effective_diagram_type}")

            # è·å–æœ‰æ•ˆé…ç½®ï¼ˆä¼˜å…ˆä½¿ç”¨ä¼ å…¥å‚æ•°ï¼Œå¦åˆ™ä½¿ç”¨é»˜è®¤é¢„è®¾ï¼‰
            presets_service = get_model_presets_service()
            config = presets_service.get_active_config(
                provider=selected_provider,
                api_key=api_key or request.api_key,
                base_url=base_url or request.base_url,
                model_name=model_name or request.model_name
            )

            if not config:
                return ChatGenerationResponse(
                    success=False,
                    nodes=[],
                    edges=[],
                    mermaid_code="",
                    message="No AI configuration found. Please configure AI model in settings or provide API key."
                )

            vision_service = create_vision_service(
                provider=config["provider"],
                api_key=config["api_key"],
                base_url=config.get("base_url"),
                model_name=config.get("model_name"),
            )

            prompt_request = request.model_copy(update={"diagram_type": effective_diagram_type})
            prompt = self._build_generation_prompt(prompt_request)

            logger.info(f"[CHAT-GEN] Calling AI with provider: {selected_provider}")
            logger.info(f"[CHAT-GEN] Prompt (first 200 chars): {prompt[:200]}...")
            ai_raw = await self._call_ai_text_generation(vision_service, prompt, selected_provider)
            logger.info(f"[CHAT-GEN] AI raw response (first 500 chars): {ai_raw[:500]}...")
            ai_data = self._safe_json(ai_raw)
            logger.info(f"[CHAT-GEN] Parsed AI data keys: {list(ai_data.keys())}")

            if effective_diagram_type == "architecture":
                # Pass architecture_type to normalization
                arch_type = request.architecture_type or "layered"
                nodes, edges, mermaid_code = self._normalize_architecture_graph(ai_data, arch_type)

                # Only suppress edges if template says not to show them
                template = ARCHITECTURE_TEMPLATES.get(arch_type, ARCHITECTURE_TEMPLATES["layered"])
                if not template.get("show_edges", False):
                    edges = []  # Business and layered architectures don't show edges
                # Technical and deployment architectures will keep their edges
            else:
                nodes, edges, mermaid_code = self._normalize_ai_graph(ai_data)

            logger.info(f"[CHAT-GEN] After normalization: {len(nodes)} nodes, {len(edges)} edges")

            if not nodes:
                logger.warning(
                    "[CHAT-GEN] AI response missing nodes; raw keys: %s",
                    list(ai_data.keys()),
                )
                raise ValueError("AI response missing nodes; please retry with clearer input.")

            # If AI result is completely empty, use template mock as last resort
            # Changed from < 3 nodes to == 0 nodes to be less aggressive
            should_use_fallback = (
                effective_diagram_type == "flow"
                and len(nodes) == 0
                and request.template_id  # Only use template mock if a template was selected
            )

            if should_use_fallback:
                logger.warning(
                    "[CHAT-GEN] AI returned NO nodes; using template fallback"
                )
                if request.template_id == "microservice-architecture":
                    mock_result = self._mock_microservice_architecture()
                elif request.template_id == "high-concurrency-system":
                    mock_result = self._mock_high_concurrency()
                else:
                    mock_result = self._mock_oom_investigation()
                nodes = mock_result["nodes"]
                edges = mock_result["edges"]
                mermaid_code = mock_result["mermaid_code"]
                message = (
                    f"AI returned no nodes; using template mock"
                )
            else:
                message = f"Generated via {selected_provider}"
                logger.info(f"[CHAT-GEN] Using AI result (not falling back to mock)")

            logger.info(
                f"[CHAT-GEN] Generated via {selected_provider}: {len(nodes)} nodes, {len(edges)} edges"
            )
            return ChatGenerationResponse(
                nodes=nodes,
                edges=edges,
                mermaid_code=mermaid_code,
                success=True,
                message=message,
            )

        except Exception as e:
            logger.error(f"Flowchart generation failed: {e}", exc_info=True)
            # DO NOT return mock data - let the error propagate to the client
            raise HTTPException(
                status_code=500,
                detail=f"AI generation failed: {str(e)}. Please check your API key and try again."
            )


def create_chat_generator_service() -> ChatGeneratorService:
    """Create service instance."""
    return ChatGeneratorService()
