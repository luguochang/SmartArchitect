"""
ä¸“ä¸šæ¼”è®²ç¨¿ç”ŸæˆæœåŠ¡
åŸºäºCO-STARæ¡†æ¶å’ŒRAGå¢å¼º

Author: SmartArchitect Team
Date: 2026-01-22
"""

from typing import List, Optional, Dict, AsyncGenerator
from collections import Counter
import json
import logging
import asyncio
from pathlib import Path

from app.models.schemas import (
    Node, Edge, ScriptOptions, ScriptContent, ScriptMetadata,
    StreamEvent, EnhancedSpeechScriptRequest
)

logger = logging.getLogger(__name__)


class ProfessionalPromptBuilder:
    """
    ä¸“ä¸šæ¼”è®²ç¨¿Promptæ„å»ºå™¨
    åŸºäºCO-STARæ¡†æ¶ + Role-based prompting + æ¼”è®²ç¨¿è¦ç´ çº¦æŸ

    å‚è€ƒ:
    - https://www.lakera.ai/blog/prompt-engineering-guide
    - https://www.ibm.com/think/prompt-engineering
    """

    def __init__(self):
        # æ¼”è®²ç¨¿å¿…éœ€è¦ç´ ï¼ˆçº¦æŸå¤§æ¨¡å‹ç”Ÿæˆé«˜è´¨é‡å†…å®¹ï¼‰
        self.duration_specs = {
            "30s": {
                "words": "120-160",
                "structure": "Hook (10s) + Value Proposition (15s) + Call-to-Action (5s)",
                "required_elements": [
                    "å¼€åœºHookï¼ˆç”¨é—®é¢˜æˆ–æ•°æ®å¸å¼•æ³¨æ„ï¼‰",
                    "æ ¸å¿ƒä»·å€¼é™ˆè¿°ï¼ˆ1-2å¥è¯ï¼‰",
                    "å…³é”®æŒ‡æ ‡æˆ–äº®ç‚¹ï¼ˆ1ä¸ªæ•°å­—ï¼‰",
                    "è¡ŒåŠ¨å·å¬"
                ],
                "tone": "ç®€æ´æœ‰åŠ›ï¼Œèšç„¦ä»·å€¼"
            },
            "2min": {
                "words": "560-640",
                "structure": "å¼€åœº(30s) + é—®é¢˜èƒŒæ™¯(30s) + è§£å†³æ–¹æ¡ˆ(45s) + ä»·å€¼è¯æ˜(30s) + ç»“å°¾(15s)",
                "required_elements": [
                    "å¼€åœºæ•…äº‹æˆ–åœºæ™¯ï¼ˆå¼•å‘å…±é¸£ï¼‰",
                    "å½“å‰ç—›ç‚¹/æŒ‘æˆ˜çš„æ¸…æ™°é™ˆè¿°",
                    "æ¶æ„è®¾è®¡çš„3ä¸ªæ ¸å¿ƒäº®ç‚¹",
                    "RAGæ¡ˆä¾‹æ”¯æ’‘ï¼ˆè‡³å°‘1ä¸ªå…·ä½“ä¾‹å­ï¼‰",
                    "é‡åŒ–ä»·å€¼ï¼ˆæ€§èƒ½/æˆæœ¬/å¯é æ€§æŒ‡æ ‡ï¼‰",
                    "ä¸‹ä¸€æ­¥è¡ŒåŠ¨æˆ–å»ºè®®"
                ],
                "tone": "ä¸“ä¸šä½†æ˜“æ‡‚ï¼Œé€»è¾‘æ¸…æ™°"
            },
            "5min": {
                "words": "1400-1600",
                "structure": "å¼€åœº(1min) + èƒŒæ™¯(1min) + æ¶æ„è®¾è®¡(2min) + é£é™©ä¸å¯¹ç­–(0.5min) + Q&Aå¼•å¯¼(0.5min)",
                "required_elements": [
                    "å¼•äººå…¥èƒœçš„å¼€åœºï¼ˆæ•…äº‹/ç»Ÿè®¡/é—®é¢˜ï¼‰",
                    "ä¸šåŠ¡èƒŒæ™¯å’ŒæŠ€æœ¯æŒ‘æˆ˜",
                    "æ¶æ„è®¾è®¡ç†å¿µå’Œæƒè¡¡å†³ç­–",
                    "æ ¸å¿ƒç»„ä»¶æ·±å…¥è®²è§£ï¼ˆ3-5ä¸ªï¼‰",
                    "æ•°æ®æµå’Œå…³é”®è·¯å¾„åˆ†æ",
                    "RAGæœ€ä½³å®è·µå¼•ç”¨ï¼ˆè‡³å°‘2ä¸ªï¼‰",
                    "ç›¸ä¼¼æ¡ˆä¾‹å¯¹æ¯”ï¼ˆä»RAGè·å–ï¼‰",
                    "å·²çŸ¥é£é™©å’Œç¼“è§£æªæ–½",
                    "æ€§èƒ½/æˆæœ¬/æ‰©å±•æ€§åˆ†æ",
                    "æœªæ¥æ¼”è¿›æ–¹å‘",
                    "å¼€æ”¾å¼é—®é¢˜å¼•å¯¼è®¨è®º"
                ],
                "tone": "æ·±å…¥æµ…å‡ºï¼Œå…¼é¡¾å¹¿åº¦ä¸æ·±åº¦"
            }
        }

    def build_script_prompt(
        self,
        nodes: List[Node],
        edges: List[Edge],
        duration: str,
        rag_context: Optional[Dict] = None,
        options: Optional[ScriptOptions] = None
    ) -> str:
        """
        æ„å»ºçº¦æŸå¼ä¸“ä¸šæ¼”è®²ç¨¿ç”Ÿæˆprompt
        """
        if options is None:
            options = ScriptOptions()

        spec = self.duration_specs[duration]

        # === CO-STARæ¡†æ¶æ„å»º ===

        # C - Context (ä¸Šä¸‹æ–‡)
        context_section = f"""
## ğŸ“‹ CONTEXT (ä¸Šä¸‹æ–‡èƒŒæ™¯)

### å½“å‰æ¶æ„æ¦‚è§ˆ
{self._format_architecture_detailed(nodes, edges)}

### çŸ¥è¯†åº“æ£€ç´¢ç»“æœï¼ˆå…¬å¸æœ€ä½³å®è·µï¼‰
{self._format_rag_context_structured(rag_context) if rag_context else "ï¼ˆæš‚æ— RAGä¸Šä¸‹æ–‡ï¼‰"}

### æ£€æµ‹åˆ°çš„æ¶æ„æ¨¡å¼
- æŠ€æœ¯æ ˆ: {self._extract_tech_stack(nodes)}
- å¤æ‚åº¦: {self._assess_complexity(nodes, edges)}
"""

        # O - Objective (ç›®æ ‡)
        objective_section = f"""
## ğŸ¯ OBJECTIVE (ç”Ÿæˆç›®æ ‡)

ä½ çš„ä»»åŠ¡æ˜¯ä¸ºè¿™ä¸ªæŠ€æœ¯æ¶æ„ç”Ÿæˆä¸€ä»½**ä¸“ä¸šã€æœ‰æ·±åº¦ã€æœ‰è¯´æœåŠ›**çš„{duration}æ¼”è®²ç¨¿ã€‚

ç›®æ ‡å—ä¼—: {options.audience}
- å¦‚æœæ˜¯é«˜ç®¡: å¼ºè°ƒå•†ä¸šä»·å€¼ã€ROIã€é£é™©æ§åˆ¶
- å¦‚æœæ˜¯æŠ€æœ¯å›¢é˜Ÿ: æ·±å…¥æŠ€æœ¯ç»†èŠ‚ã€è®¾è®¡æƒè¡¡ã€æœ€ä½³å®è·µ
- å¦‚æœæ˜¯æ··åˆå—ä¼—: åˆ†å±‚è¡¨è¾¾ï¼Œå…ˆè®²ä»·å€¼å†è®²å®ç°

é‡ç‚¹å…³æ³¨: {', '.join(options.focus_areas)}
"""

        # S - Style (é£æ ¼)
        style_section = f"""
## ğŸ¨ STYLE (æ¼”è®²é£æ ¼)

å†™ä½œé£æ ¼è¦æ±‚:
1. ä½¿ç”¨**è®²æ•…äº‹**çš„æ–¹å¼ï¼Œä¸è¦å¹²å·´å·´çš„åˆ—ä¸¾
2. å¤šç”¨**ç±»æ¯”å’Œæ¯”å–»**è®©å¤æ‚æ¦‚å¿µæ˜“æ‡‚ï¼ˆå¦‚ï¼š"APIç½‘å…³å°±åƒæœºåœºå®‰æ£€"ï¼‰
3. **æ•°æ®é©±åŠ¨**: å¼•ç”¨å…·ä½“æ•°å­—ã€ç™¾åˆ†æ¯”ã€å¯¹æ¯”ï¼ˆä»RAGä¸Šä¸‹æ–‡è·å–ï¼‰
4. **é—®é¢˜å¯¼å‘**: å…ˆæå‡ºé—®é¢˜ï¼Œå†å±•ç¤ºè§£å†³æ–¹æ¡ˆ
5. **èŠ‚å¥æ§åˆ¶**: {spec['structure']}

å‚è€ƒä¼˜ç§€æŠ€æœ¯æ¼”è®²:
- Martin Fowlerçš„æ¶æ„æ¼”è®²ï¼ˆæ¸…æ™°çš„å±‚æ¬¡ç»“æ„ï¼‰
- Simon Sinekçš„TEDæ¼”è®²ï¼ˆä»Whyå¼€å§‹ï¼‰
- Amazon CTO Werner Vogelsçš„æŠ€æœ¯åˆ†äº«ï¼ˆæ¡ˆä¾‹ä¸°å¯Œï¼‰
"""

        # T - Tone (è¯­æ°”)
        tone_section = f"""
## ğŸ—£ï¸ TONE (è¯­æ°”åŸºè°ƒ)

è¯­æ°”è®¾å®š: {options.tone} + {spec['tone']}

å…·ä½“è¦æ±‚:
- âœ… è‡ªä¿¡ä½†ä¸å‚²æ…¢: "æˆ‘ä»¬çš„æ¶æ„..."ï¼ˆä¸æ˜¯"æˆ‘è§‰å¾—..."ï¼‰
- âœ… ä¸“ä¸šä½†ä¸æ™¦æ¶©: é¿å…è¿‡åº¦ä½¿ç”¨è¡Œè¯ï¼Œå¿…è¦æ—¶è§£é‡Šæœ¯è¯­
- âœ… è¯šå®ä¸”é€æ˜: æ‰¿è®¤trade-offså’Œå·²çŸ¥é™åˆ¶
- âœ… ç§¯æä¸”å»ºè®¾æ€§: å³ä½¿è®¨è®ºé—®é¢˜ï¼Œä¹Ÿè¦ç»™å‡ºè§£å†³è·¯å¾„
- âŒ é¿å…ç©ºæ´è¡¨è¿°: "éå¸¸å¥½"ã€"å¾ˆå¼ºå¤§"ç­‰æ— å®è´¨å†…å®¹çš„ä¿®é¥°
"""

        # A - Audience (å—ä¼—)
        audience_section = f"""
## ğŸ‘¥ AUDIENCE (å—ä¼—åˆ†æ)

å—ä¼—ç±»å‹: {options.audience}

å—ä¼—æœŸå¾…:
- ä»–ä»¬æƒ³çŸ¥é“: è¿™ä¸ªæ¶æ„èƒ½è§£å†³ä»€ä¹ˆé—®é¢˜ï¼Ÿ
- ä»–ä»¬å…³å¿ƒçš„: {self._get_audience_concerns(options.audience)}
- ä»–ä»¬çš„èƒŒæ™¯: {self._get_audience_background(options.audience)}

è°ƒæ•´ç­–ç•¥:
- æŠ€æœ¯æ·±åº¦: {self._get_technical_depth(options.audience)}
- æœ¯è¯­ä½¿ç”¨: {self._get_terminology_guidance(options.audience)}
- ä¸¾ä¾‹æ–¹å¼: {self._get_example_style(options.audience)}
"""

        # R - Response Format (å“åº”æ ¼å¼)
        response_format_section = f"""
## ğŸ“ RESPONSE FORMAT (è¾“å‡ºæ ¼å¼)

ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹ç»“æ„è¾“å‡º:

[INTRO]
{self._generate_intro_template(spec)}

[BODY]
{self._generate_body_template(spec, nodes, edges)}

[CONCLUSION]
{self._generate_conclusion_template(spec)}

## âš ï¸ è´¨é‡æ£€æŸ¥æ¸…å•ï¼ˆç”Ÿæˆåè‡ªæŸ¥ï¼‰
{self._generate_quality_checklist(spec)}
"""

        # === æ•´åˆæœ€ç»ˆPrompt ===
        final_prompt = f"""
{context_section}

{objective_section}

{style_section}

{tone_section}

{audience_section}

{response_format_section}

---

## ğŸš€ NOW BEGIN GENERATION

æ—¶é•¿: {duration} (ç›®æ ‡å­—æ•°: {spec['words']}å­—)

å¿…é¡»åŒ…å«çš„è¦ç´ :
{chr(10).join(f"- {elem}" for elem in spec['required_elements'])}

è®°ä½:
1. ä»RAGä¸Šä¸‹æ–‡ä¸­è‡³å°‘å¼•ç”¨2ä¸ªå…·ä½“æ¡ˆä¾‹æˆ–æœ€ä½³å®è·µï¼ˆæ ‡æ³¨æ¥æºï¼‰
2. æ¯ä¸ªæ–­è¨€éƒ½è¦æœ‰æ•°æ®æˆ–æ¡ˆä¾‹æ”¯æ’‘ï¼Œé¿å…ç©ºæ´è¡¨è¿°
3. ä½¿ç”¨è¿‡æ¸¡å¥è®©æ®µè½è¡”æ¥è‡ªç„¶ï¼ˆå¦‚ï¼š"é‚£ä¹ˆï¼Œæˆ‘ä»¬æ˜¯å¦‚ä½•å®ç°è¿™ä¸€ç‚¹çš„å‘¢ï¼Ÿ"ï¼‰
4. åœ¨å…³é”®ç‚¹ä½¿ç”¨**é‡å¤å’Œå¼ºè°ƒ**ï¼ˆé‡è¦çš„è¯è¯´ä¸‰éï¼‰
5. ç»“å°¾è¦æœ‰æ˜ç¡®çš„è¡ŒåŠ¨å·å¬æˆ–æ€è€ƒé—®é¢˜

å¼€å§‹ç”Ÿæˆæ¼”è®²ç¨¿:
"""

        return final_prompt

    def _format_architecture_detailed(self, nodes: List[Node], edges: List[Edge]) -> str:
        """è¯¦ç»†æ ¼å¼åŒ–æ¶æ„ä¿¡æ¯"""
        components_by_type = {}
        for node in nodes:
            node_type = node.type or "default"
            if node_type not in components_by_type:
                components_by_type[node_type] = []
            components_by_type[node_type].append(node.data.label)

        arch_summary = f"**ç»„ä»¶æ€»æ•°**: {len(nodes)}\n\n**ç»„ä»¶åˆ†å¸ƒ**:\n"
        for node_type, labels in components_by_type.items():
            arch_summary += f"- {node_type.capitalize()}: {len(labels)}ä¸ª ({', '.join(labels[:3])}{'...' if len(labels) > 3 else ''})\n"

        arch_summary += f"\n**è¿æ¥æ€»æ•°**: {len(edges)}\n"
        if edges:
            key_flows = edges[:5]
            arch_summary += "**å…³é”®æ•°æ®æµ**:\n"
            for edge in key_flows:
                label_str = f" ({edge.label})" if edge.label else ""
                arch_summary += f"- {edge.source} â†’ {edge.target}{label_str}\n"

        return arch_summary

    def _format_rag_context_structured(self, rag_context: Optional[Dict]) -> str:
        """æ ¼å¼åŒ–RAGä¸Šä¸‹æ–‡"""
        if not rag_context:
            return "ï¼ˆæš‚æ— ç›¸å…³æ–‡æ¡£ï¼‰"

        chunks = rag_context.get("chunks", [])
        if not chunks:
            return "ï¼ˆæš‚æ— ç›¸å…³æ–‡æ¡£ï¼‰"

        formatted = f"æ‰¾åˆ° {len(chunks)} ä¸ªç›¸å…³æ–‡æ¡£ç‰‡æ®µ:\n\n"
        for i, chunk in enumerate(chunks[:3], 1):
            formatted += f"{i}. {chunk.get('content', '')[:200]}...\n"
            formatted += f"   æ¥æº: {chunk.get('metadata', {}).get('filename', 'Unknown')}\n\n"

        return formatted

    def _extract_tech_stack(self, nodes: List[Node]) -> str:
        """æå–æŠ€æœ¯æ ˆ"""
        # ä»èŠ‚ç‚¹ç±»å‹æ¨æ–­æŠ€æœ¯æ ˆ
        node_types = [n.type for n in nodes if n.type]
        type_counts = Counter(node_types)

        tech_stack = []
        if type_counts.get("database") or type_counts.get("storage"):
            tech_stack.append("æ•°æ®å­˜å‚¨")
        if type_counts.get("api") or type_counts.get("gateway"):
            tech_stack.append("APIç½‘å…³")
        if type_counts.get("service"):
            tech_stack.append("å¾®æœåŠ¡")
        if type_counts.get("cache"):
            tech_stack.append("ç¼“å­˜")

        return ", ".join(tech_stack) if tech_stack else "é€šç”¨æ¶æ„"

    def _assess_complexity(self, nodes: List[Node], edges: List[Edge]) -> str:
        """è¯„ä¼°æ¶æ„å¤æ‚åº¦"""
        node_count = len(nodes)
        edge_count = len(edges)

        if node_count <= 5 and edge_count <= 5:
            return "ç®€å•ï¼ˆ5ä¸ªä»¥ä¸‹ç»„ä»¶ï¼‰"
        elif node_count <= 15 and edge_count <= 20:
            return "ä¸­ç­‰ï¼ˆ5-15ä¸ªç»„ä»¶ï¼‰"
        else:
            return f"å¤æ‚ï¼ˆ{node_count}ä¸ªç»„ä»¶ï¼Œ{edge_count}ä¸ªè¿æ¥ï¼‰"

    def _generate_intro_template(self, spec: Dict) -> str:
        """ç”Ÿæˆå¼€åœºæ¨¡æ¿"""
        if spec['words'].startswith('120'):
            return """
ï¼ˆ30ç§’ç”µæ¢¯æ¼”è®²ï¼‰
- ç”¨1ä¸ªé—®é¢˜æˆ–æ•°æ®å¼€åœºï¼ˆå¸å¼•æ³¨æ„ï¼‰
- 1å¥è¯è¯´æ˜è¿™ä¸ªæ¶æ„è§£å†³ä»€ä¹ˆé—®é¢˜
- 1ä¸ªæ ¸å¿ƒäº®ç‚¹æˆ–æŒ‡æ ‡
- è¡ŒåŠ¨å·å¬
"""
        elif spec['words'].startswith('560'):
            return """
ï¼ˆ2åˆ†é’Ÿå¼€åœº - çº¦120å­—ï¼‰
- è®²ä¸€ä¸ª3-5å¥è¯çš„æ•…äº‹æˆ–åœºæ™¯ï¼ˆå¼•å‘å…±é¸£ï¼‰
- æˆ–è€…ç”¨ä¸€ä¸ªä»¤äººæƒŠè®¶çš„æ•°æ®/äº‹å®å¼€åœº
- å¿«é€Ÿè¿‡æ¸¡åˆ°å½“å‰ç—›ç‚¹
- å¼•å‡ºæ¶æ„è®¾è®¡çš„å¿…è¦æ€§

ç¤ºä¾‹: "æƒ³è±¡ä¸€ä¸‹ï¼Œå½“100ä¸‡ç”¨æˆ·åŒæ—¶æ¶Œå…¥ç³»ç»Ÿï¼Œè€Œä½ çš„æ•°æ®åº“å¼€å§‹æŠ¥è­¦ã€‚è¿™ä¸æ˜¯å‡è®¾ï¼Œè¿™æ˜¯æˆ‘ä»¬å»å¹´åŒ11é‡åˆ°çš„çœŸå®åœºæ™¯ã€‚ä»Šå¤©æˆ‘è¦åˆ†äº«çš„ï¼Œå°±æ˜¯æˆ‘ä»¬å¦‚ä½•ç”¨è¿™å¥—æ¶æ„è§£å†³è¿™ä¸ªé—®é¢˜ã€‚"
"""
        else:
            return """
ï¼ˆ5åˆ†é’Ÿå¼€åœº - çº¦300å­—ï¼‰
- ç”¨æ•…äº‹/ç»Ÿè®¡æ•°æ®/è¡Œä¸šè¶‹åŠ¿å¼€åœºï¼ˆ1-2åˆ†é’Ÿï¼‰
- å»ºç«‹ä¸šåŠ¡èƒŒæ™¯ï¼šä¸ºä»€ä¹ˆéœ€è¦è¿™ä¸ªæ¶æ„ï¼Ÿ
- æŠ€æœ¯æŒ‘æˆ˜ï¼šé¢ä¸´å“ªäº›å…·ä½“é—®é¢˜ï¼Ÿ
- ç®€è¦é¢„å‘Šï¼šæˆ‘ä»¬çš„è§£å†³æ–¹æ¡ˆçš„æ ¸å¿ƒæ€è·¯ï¼ˆ3ä¸ªå…³é”®è¯ï¼‰

ç¤ºä¾‹: "2023å¹´ï¼ŒGartneræŠ¥å‘ŠæŒ‡å‡ºï¼Œ75%çš„ä¼ä¸šåœ¨æ•°å­—åŒ–è½¬å‹ä¸­é‡åˆ°æ¶æ„ç“¶é¢ˆã€‚æˆ‘ä»¬å…¬å¸ä¹Ÿä¸ä¾‹å¤–ã€‚å»å¹´ï¼Œæˆ‘ä»¬çš„å•ä½“åº”ç”¨å¼€å§‹å‡ºç°æ€§èƒ½é—®é¢˜ï¼Œå“åº”æ—¶é—´ä»200msé£™å‡åˆ°3ç§’ï¼Œç”¨æˆ·æŠ•è¯‰æ¿€å¢ã€‚ç»è¿‡6ä¸ªæœˆçš„æ¶æ„é‡æ„ï¼Œæˆ‘ä»¬ä¸ä»…è§£å†³äº†æ€§èƒ½é—®é¢˜ï¼Œè¿˜å°†éƒ¨ç½²é¢‘ç‡ä»æ¯æœˆ1æ¬¡æå‡åˆ°æ¯å¤©10æ¬¡ã€‚ä»Šå¤©ï¼Œæˆ‘æƒ³åˆ†äº«è¿™ä¸ªæ¶æ„èƒŒåçš„è®¾è®¡æ€è·¯å’Œå®è·µç»éªŒã€‚"
"""

    def _generate_body_template(self, spec: Dict, nodes: List[Node], edges: List[Edge]) -> str:
        """ç”Ÿæˆä¸»ä½“æ¨¡æ¿"""
        if spec['words'].startswith('120'):
            return "ï¼ˆ30ç§’ä¸»ä½“ï¼‰ç›´æ¥è¯´æ ¸å¿ƒä»·å€¼å’Œå…³é”®æŒ‡æ ‡ï¼Œä¸å±•å¼€ç»†èŠ‚"
        elif spec['words'].startswith('560'):
            return """
ï¼ˆ2åˆ†é’Ÿä¸»ä½“ - çº¦400å­—ï¼‰

åˆ†3ä¸ªæ®µè½:

**æ®µè½1: æ¶æ„è®¾è®¡æ ¸å¿ƒæ€è·¯ï¼ˆ120å­—ï¼‰**
- æˆ‘ä»¬é‡‡ç”¨äº†ä»€ä¹ˆæ¶æ„æ¨¡å¼ï¼Ÿï¼ˆä»RAGä¸Šä¸‹æ–‡å¼•ç”¨ï¼‰
- ä¸ºä»€ä¹ˆé€‰æ‹©è¿™ä¸ªæ–¹æ¡ˆï¼Ÿï¼ˆæƒè¡¡å†³ç­–ï¼‰
- ä¸ä¼ ç»Ÿæ–¹æ¡ˆçš„å¯¹æ¯”

**æ®µè½2: å…³é”®ç»„ä»¶å’Œæ•°æ®æµï¼ˆ160å­—ï¼‰**
- 3ä¸ªæœ€é‡è¦çš„ç»„ä»¶åŠå…¶èŒè´£
- æ ¸å¿ƒæ•°æ®æµè·¯å¾„
- ç”¨ç±»æ¯”è®©éæŠ€æœ¯å—ä¼—ä¹Ÿèƒ½ç†è§£

**æ®µè½3: ä»·å€¼è¯æ˜ï¼ˆ120å­—ï¼‰**
- æ€§èƒ½æå‡: XX%ï¼ˆå…·ä½“æ•°å­—ï¼‰
- æˆæœ¬ä¼˜åŒ–: èŠ‚çœXXï¼ˆå…·ä½“é‡‘é¢ï¼‰
- æˆ–å¼•ç”¨RAGä¸­çš„ç›¸ä¼¼æ¡ˆä¾‹: "è¿™ç§æ¶æ„åœ¨XXå…¬å¸ä¹Ÿå–å¾—äº†ç±»ä¼¼æ•ˆæœ..."
"""
        else:
            return """
ï¼ˆ5åˆ†é’Ÿä¸»ä½“ - çº¦1000å­—ï¼‰

åˆ†5ä¸ªæ®µè½:

**æ®µè½1: æ¶æ„è®¾è®¡ç†å¿µï¼ˆ200å­—ï¼‰**
- è®¾è®¡åŸåˆ™ï¼ˆå¦‚ï¼šé«˜å†…èšä½è€¦åˆã€å•ä¸€èŒè´£ï¼‰
- ä¸ºä»€ä¹ˆé€‰æ‹©è¿™äº›åŸåˆ™ï¼Ÿï¼ˆç»“åˆä¸šåŠ¡åœºæ™¯ï¼‰
- ä»RAGå¼•ç”¨ä¸šç•Œæœ€ä½³å®è·µ

**æ®µè½2-4: æ ¸å¿ƒç»„ä»¶æ·±å…¥è®²è§£ï¼ˆæ¯ä¸ªç»„ä»¶160-200å­—ï¼‰**
é€‰æ‹©3-4ä¸ªæœ€é‡è¦çš„ç»„ä»¶:
- ç»„ä»¶çš„èŒè´£å’Œè®¾è®¡è€ƒé‡
- æŠ€æœ¯é€‰å‹çš„æƒè¡¡ï¼ˆä¸ºä»€ä¹ˆç”¨Redisè€Œä¸æ˜¯Memcachedï¼Ÿï¼‰
- æ€§èƒ½æ•°æ®æˆ–å‹æµ‹ç»“æœ
- ä»RAGå¼•ç”¨ç›¸ä¼¼æ¡ˆä¾‹æˆ–åæ¨¡å¼

**æ®µè½5: é£é™©ä¸å¯¹ç­–ï¼ˆ200å­—ï¼‰**
- å·²çŸ¥çš„æŠ€æœ¯é£é™©ï¼ˆä¸è¦å›é¿ï¼‰
- ç¼“è§£æªæ–½å’Œå¤‡é€‰æ–¹æ¡ˆ
- ç›‘æ§å’Œå‘Šè­¦ç­–ç•¥

**æ®µè½6: ä»·å€¼æ€»ç»“ï¼ˆ200å­—ï¼‰**
- é‡åŒ–çš„ä¸šåŠ¡ä»·å€¼
- æŠ€æœ¯å€ºåŠ¡çš„æ”¹å–„
- å›¢é˜Ÿæ•ˆèƒ½æå‡
"""

    def _generate_conclusion_template(self, spec: Dict) -> str:
        """ç”Ÿæˆç»“å°¾æ¨¡æ¿"""
        if spec['words'].startswith('120'):
            return "ï¼ˆ10ç§’ç»“å°¾ï¼‰æ¸…æ™°çš„è¡ŒåŠ¨å·å¬: 'Let's discuss' / 'æ¬¢è¿è¯•ç”¨' / 'æˆ‘ä»¬å¯ä»¥å¸®ä½ å®ç°'"
        elif spec['words'].startswith('560'):
            return """
ï¼ˆ2åˆ†é’Ÿç»“å°¾ - çº¦80å­—ï¼‰
- å›é¡¾æ ¸å¿ƒä»·å€¼ï¼ˆ1å¥è¯ï¼‰
- è¡ŒåŠ¨å·å¬æˆ–ä¸‹ä¸€æ­¥å»ºè®®
- ç•™ä¸€ä¸ªå¼€æ”¾å¼é—®é¢˜å¼•å‘æ€è€ƒ

ç¤ºä¾‹: "é€šè¿‡è¿™å¥—æ¶æ„ï¼Œæˆ‘ä»¬ä¸ä»…è§£å†³äº†æ€§èƒ½é—®é¢˜ï¼Œæ›´é‡è¦çš„æ˜¯å»ºç«‹äº†ä¸€ä¸ªå¯æŒç»­æ¼”è¿›çš„æŠ€æœ¯ä½“ç³»ã€‚å¦‚æœä½ ä¹Ÿé¢ä¸´ç±»ä¼¼æŒ‘æˆ˜ï¼Œä¸å¦¨æ€è€ƒä¸€ä¸‹ï¼šä½ çš„æ¶æ„æ˜¯å¦ä¸ºæœªæ¥çš„å¢é•¿é¢„ç•™äº†ç©ºé—´ï¼Ÿ"
"""
        else:
            return """
ï¼ˆ5åˆ†é’Ÿç»“å°¾ - çº¦200å­—ï¼‰
- æ€»ç»“3ä¸ªå…³é”®è¦ç‚¹ï¼ˆå‘¼åº”å¼€åœºï¼‰
- æœªæ¥æ¼”è¿›æ–¹å‘
- æŠ›å‡º2-3ä¸ªæ€è€ƒé—®é¢˜å¼•å¯¼Q&A
- æ„Ÿè°¢å’Œè”ç³»æ–¹å¼

ç¤ºä¾‹: "ä»Šå¤©æˆ‘ä»¬åˆ†äº«äº†ä»å•ä½“åˆ°å¾®æœåŠ¡çš„æ¶æ„æ¼”è¿›ä¹‹è·¯ã€‚æ ¸å¿ƒè¦ç‚¹æœ‰ä¸‰ä¸ªï¼šç¬¬ä¸€ï¼Œæ¸è¿›å¼è¿ç§»æ¯”å¤§çˆ†ç‚¸é‡å†™æ›´å®‰å…¨ï¼›ç¬¬äºŒï¼Œè§‚æµ‹æ€§æ˜¯å¾®æœåŠ¡æ¶æ„çš„ç”Ÿå‘½çº¿ï¼›ç¬¬ä¸‰ï¼Œå›¢é˜Ÿç»„ç»‡è¦ä¸æ¶æ„å¯¹é½ã€‚æœªæ¥ï¼Œæˆ‘ä»¬è®¡åˆ’å¼•å…¥æœåŠ¡ç½‘æ ¼å’Œè¾¹ç¼˜è®¡ç®—èƒ½åŠ›ã€‚æˆ‘æƒ³ç•™å‡ ä¸ªé—®é¢˜ç»™å¤§å®¶ï¼š1) ä½ ä»¬å¦‚ä½•å¤„ç†å¾®æœåŠ¡çš„åˆ†å¸ƒå¼äº‹åŠ¡ï¼Ÿ2) åœ¨ä½ ä»¬çš„åœºæ™¯ä¸­ï¼ŒæœåŠ¡ç²’åº¦å¦‚ä½•åˆ’åˆ†ï¼Ÿæ¬¢è¿ä¼šåäº¤æµã€‚è°¢è°¢å¤§å®¶ï¼"
"""

    def _generate_quality_checklist(self, spec: Dict) -> str:
        """ç”Ÿæˆè´¨é‡æ£€æŸ¥æ¸…å•"""
        return f"""
ç”Ÿæˆåè¯·è‡ªæŸ¥:
- [ ] å­—æ•°åœ¨ç›®æ ‡èŒƒå›´å†…ï¼ˆ{spec['words']}å­—ï¼‰
- [ ] æ‰€æœ‰å¿…éœ€è¦ç´ éƒ½åŒ…å«
- [ ] è‡³å°‘å¼•ç”¨äº†2ä¸ªRAGä¸Šä¸‹æ–‡ä¸­çš„æ¡ˆä¾‹/æœ€ä½³å®è·µ
- [ ] æ¯ä¸ªæŠ€æœ¯æ–­è¨€éƒ½æœ‰æ•°æ®æˆ–æ¡ˆä¾‹æ”¯æ’‘
- [ ] æ®µè½ä¹‹é—´æœ‰è‡ªç„¶çš„è¿‡æ¸¡
- [ ] å¼€åœºæœ‰å¸å¼•åŠ›ï¼ˆä¸æ˜¯å¹³é“ºç›´å™ï¼‰
- [ ] ç»“å°¾æœ‰æ˜ç¡®çš„è¡ŒåŠ¨å·å¬æˆ–æ€è€ƒé—®é¢˜
- [ ] é¿å…ä½¿ç”¨"éå¸¸å¥½"ã€"å¾ˆå¼ºå¤§"ç­‰ç©ºæ´è¡¨è¿°
- [ ] æŠ€æœ¯æœ¯è¯­æœ‰å¿…è¦çš„è§£é‡Šï¼ˆå°¤å…¶å¯¹éæŠ€æœ¯å—ä¼—ï¼‰
"""

    def _get_audience_concerns(self, audience: str) -> str:
        """æ ¹æ®å—ä¼—è¿”å›å…³æ³¨ç‚¹"""
        concerns = {
            "executive": "ROIã€ä¸šåŠ¡å½±å“ã€é£é™©æ§åˆ¶ã€ç«äº‰ä¼˜åŠ¿",
            "technical": "æŠ€æœ¯ç»†èŠ‚ã€æ€§èƒ½æŒ‡æ ‡ã€å¯ç»´æŠ¤æ€§ã€æŠ€æœ¯å€ºåŠ¡",
            "mixed": "ä¸šåŠ¡ä»·å€¼ + æŠ€æœ¯äº®ç‚¹çš„å¹³è¡¡"
        }
        return concerns.get(audience, "ä¸šåŠ¡ä»·å€¼å’ŒæŠ€æœ¯å®ç°çš„å¹³è¡¡")

    def _get_audience_background(self, audience: str) -> str:
        """æ ¹æ®å—ä¼—è¿”å›èƒŒæ™¯"""
        backgrounds = {
            "executive": "é«˜ç®¡èƒŒæ™¯ï¼Œå…³æ³¨æˆ˜ç•¥å’ŒROIï¼Œä¸ç†Ÿæ‚‰æŠ€æœ¯ç»†èŠ‚",
            "technical": "æŠ€æœ¯èƒŒæ™¯ï¼Œç†Ÿæ‚‰ä¸“ä¸šæœ¯è¯­ï¼Œå…³æ³¨å®ç°ç»†èŠ‚",
            "mixed": "æ··åˆèƒŒæ™¯ï¼ŒåŒ…å«æŠ€æœ¯å’ŒéæŠ€æœ¯äººå‘˜"
        }
        return backgrounds.get(audience, "æ··åˆèƒŒæ™¯")

    def _get_technical_depth(self, audience: str) -> str:
        """è¿”å›æŠ€æœ¯æ·±åº¦æŒ‡å¯¼"""
        depth = {
            "executive": "é«˜å±‚æ¬¡ï¼Œå°‘ç”¨æŠ€æœ¯æœ¯è¯­ï¼Œå¤šè®²ä¸šåŠ¡ä»·å€¼",
            "technical": "æ·±å…¥æŠ€æœ¯ç»†èŠ‚ï¼Œå¯ä»¥ä½¿ç”¨ä¸“ä¸šæœ¯è¯­ï¼Œä½†è¦è§£é‡Šè®¾è®¡å†³ç­–",
            "mixed": "åˆ†å±‚è¡¨è¾¾ï¼šå…ˆè®²whatå’Œwhyï¼ˆä¸šåŠ¡ä»·å€¼ï¼‰ï¼Œå†è®²howï¼ˆæŠ€æœ¯å®ç°ï¼‰"
        }
        return depth.get(audience, "ä¸­ç­‰æ·±åº¦ï¼Œå…¼é¡¾ä¸šåŠ¡å’ŒæŠ€æœ¯")

    def _get_terminology_guidance(self, audience: str) -> str:
        """è¿”å›æœ¯è¯­ä½¿ç”¨æŒ‡å¯¼"""
        guidance = {
            "executive": "é¿å…æŠ€æœ¯æœ¯è¯­ï¼Œå¿…è¦æ—¶ç”¨ç±»æ¯”è§£é‡Š",
            "technical": "å¯ä»¥ä½¿ç”¨ä¸“ä¸šæœ¯è¯­ï¼Œä½†è¦è§£é‡Šå…³é”®æ¦‚å¿µ",
            "mixed": "æŠ€æœ¯æœ¯è¯­ååŠ ç®€å•è§£é‡Šï¼ˆå¦‚ï¼š'å¾®æœåŠ¡ï¼Œå³å°†ç³»ç»Ÿæ‹†åˆ†ä¸ºç‹¬ç«‹çš„å°æœåŠ¡'ï¼‰"
        }
        return guidance.get(audience, "é€‚åº¦ä½¿ç”¨ï¼ŒåŠ ä»¥è§£é‡Š")

    def _get_example_style(self, audience: str) -> str:
        """è¿”å›ä¸¾ä¾‹æ–¹å¼"""
        styles = {
            "executive": "ç”¨å•†ä¸šæ¡ˆä¾‹ï¼Œå¼•ç”¨çŸ¥åå…¬å¸ï¼ˆå¦‚ï¼šAmazonã€Netflixï¼‰",
            "technical": "ç”¨æŠ€æœ¯æ¡ˆä¾‹ï¼Œå¼•ç”¨å…·ä½“æŠ€æœ¯æ ˆå’Œæ•°æ®",
            "mixed": "å…ˆè®²å•†ä¸šä»·å€¼ï¼Œå†è®²æŠ€æœ¯ç»†èŠ‚"
        }
        return styles.get(audience, "å…¼é¡¾å•†ä¸šå’ŒæŠ€æœ¯æ¡ˆä¾‹")


class RAGSpeechScriptGenerator:
    """
    æ¼”è®²ç¨¿ç”Ÿæˆå™¨ï¼ˆå¸¦RAGå¢å¼ºå’Œæµå¼ä¼ è¾“ï¼‰
    """

    def __init__(self, rag_service=None, ai_service=None):
        self.prompt_builder = ProfessionalPromptBuilder()
        self.rag_service = rag_service
        self.ai_service = ai_service
        logger.info(f"RAGSpeechScriptGenerator initialized with AI service: {ai_service is not None}")

    async def generate_speech_script_stream(
        self,
        nodes: List[Node],
        edges: List[Edge],
        duration: str,
        options: Optional[ScriptOptions] = None
    ) -> AsyncGenerator[StreamEvent, None]:
        """
        æµå¼ç”Ÿæˆæ¼”è®²ç¨¿

        Yields:
            StreamEvent: æµå¼äº‹ä»¶ï¼ˆCONTEXT_SEARCH, CONTEXT_FOUND, TOKEN, COMPLETEç­‰ï¼‰
        """
        if options is None:
            options = ScriptOptions()

        try:
            # Phase 1: RAGä¸Šä¸‹æ–‡æ£€ç´¢
            yield StreamEvent(
                type="CONTEXT_SEARCH",
                data={"status": "æœç´¢çŸ¥è¯†åº“..."}
            )

            rag_context = None
            if self.rag_service:
                try:
                    # æ„å»ºæŸ¥è¯¢
                    query = self.build_context_query(nodes, edges, duration)

                    # è°ƒç”¨RAGæœåŠ¡ï¼ˆè¿™é‡Œéœ€è¦å®ç°RAGæœåŠ¡çš„é›†æˆï¼‰
                    # rag_context = await self.rag_service.search(query, top_k=10)

                    # ä¸´æ—¶mockæ•°æ®ï¼ˆå®é™…åº”è°ƒç”¨RAGæœåŠ¡ï¼‰
                    rag_context = {
                        "chunks": [],
                        "query": query
                    }

                    yield StreamEvent(
                        type="CONTEXT_FOUND",
                        data={
                            "chunks_found": len(rag_context.get("chunks", [])),
                            "patterns": [],
                            "sources": []
                        }
                    )
                except Exception as e:
                    # RAGå¤±è´¥ä¸å½±å“ç”Ÿæˆï¼Œåªæ˜¯è­¦å‘Š
                    yield StreamEvent(
                        type="CONTEXT_FOUND",
                        data={
                            "chunks_found": 0,
                            "warning": f"RAGæŸ¥è¯¢å¤±è´¥: {str(e)}"
                        }
                    )
            else:
                # æ²¡æœ‰RAGæœåŠ¡ï¼Œä¹Ÿè¦å‘å‡ºCONTEXT_FOUNDäº‹ä»¶
                rag_context = {"chunks": [], "suggested_patterns": []}
                yield StreamEvent(
                    type="CONTEXT_FOUND",
                    data={
                        "chunks_found": 0,
                        "patterns": [],
                        "sources": [],
                        "note": "RAGæœåŠ¡æœªå¯ç”¨"
                    }
                )

            # Phase 2: æ„å»ºå¢å¼ºæç¤ºè¯
            prompt = self.prompt_builder.build_script_prompt(
                nodes, edges, duration, rag_context, options
            )

            # Phase 3: æµå¼ç”Ÿæˆ
            yield StreamEvent(
                type="GENERATION_START",
                data={"message": "AIæ­£åœ¨åˆ›ä½œæ¼”è®²ç¨¿ï¼Œè¯·ç¨å€™..."}
            )

            accumulated = ""
            current_section = "intro"

            # ä½¿ç”¨AIæœåŠ¡ç”Ÿæˆæ¼”è®²ç¨¿
            if self.ai_service:
                logger.info("Using AI service to generate speech script with streaming")
                try:
                    # ä½¿ç”¨çœŸæ­£çš„æµå¼ç”Ÿæˆ
                    async for chunk in self.ai_service.generate_speech_script_stream(
                        nodes=nodes,
                        edges=edges,
                        duration=duration
                    ):
                        accumulated += chunk

                        # å‘é€chunks
                        yield StreamEvent(
                            type="TOKEN",
                            data={"token": chunk, "section": current_section}
                        )

                        # æ£€æµ‹ç« èŠ‚åˆ‡æ¢ï¼ˆåŸºäºå¸¸è§çš„æ®µè½æ¨¡å¼ï¼‰
                        if "\n\n" in accumulated[-30:] and len(accumulated) > 100:
                            # ç®€å•å¯å‘å¼åˆ¤æ–­ç« èŠ‚
                            word_count = self._count_words(accumulated)
                            target = self._get_target_words(duration)

                            if current_section == "intro" and word_count > target * 0.2:
                                current_section = "body"
                                yield StreamEvent(
                                    type="SECTION_COMPLETE",
                                    data={
                                        "section": "intro",
                                        "content": ""
                                    }
                                )
                            elif current_section == "body" and word_count > target * 0.8:
                                current_section = "conclusion"
                                yield StreamEvent(
                                    type="SECTION_COMPLETE",
                                    data={
                                        "section": "body",
                                        "content": ""
                                    }
                                )

                    logger.info(f"Streaming generation completed, total length: {len(accumulated)}")

                except Exception as ai_error:
                    logger.error(f"AI service generation failed: {ai_error}", exc_info=True)
                    logger.warning("Falling back to mock data")
                    # é™çº§åˆ°Mockæ•°æ®
                    accumulated = self._generate_mock_script(nodes, edges, duration)
            else:
                logger.warning("No AI service configured, using mock data")
                # æ²¡æœ‰AIæœåŠ¡ï¼Œä½¿ç”¨Mockæ•°æ®
                mock_script = self._generate_mock_script(nodes, edges, duration)

                # æ¨¡æ‹Ÿæµå¼è¾“å‡º
                for char in mock_script:
                    accumulated += char
                    yield StreamEvent(
                        type="TOKEN",
                        data={"token": char, "section": current_section}
                    )
                    await asyncio.sleep(0.001)

                    # æ£€æµ‹ç« èŠ‚åˆ‡æ¢
                    if "[BODY]" in accumulated and current_section == "intro":
                        current_section = "body"
                        yield StreamEvent(
                            type="SECTION_COMPLETE",
                            data={
                                "section": "intro",
                                "content": self.extract_section(accumulated, "intro")
                            }
                        )
                    elif "[CONCLUSION]" in accumulated and current_section == "body":
                        current_section = "conclusion"
                        yield StreamEvent(
                            type="SECTION_COMPLETE",
                            data={
                                "section": "body",
                                "content": self.extract_section(accumulated, "body")
                            }
                        )

            # Phase 4: åå¤„ç†
            final_script = self.post_process_script(accumulated, duration)
            sections = self._split_into_sections(final_script)

            yield StreamEvent(
                type="COMPLETE",
                data={
                    "script": {
                        "intro": sections.get("intro", ""),
                        "body": sections.get("body", ""),
                        "conclusion": sections.get("conclusion", ""),
                        "full_text": final_script
                    },
                    "word_count": self._count_words(final_script),
                    "estimated_seconds": self.estimate_duration(final_script),
                    "rag_sources": []
                }
            )

        except Exception as e:
            yield StreamEvent(
                type="ERROR",
                data={"error": str(e)}
            )

    def build_context_query(
        self,
        nodes: List[Node],
        edges: List[Edge],
        duration: str
    ) -> str:
        """æ„å»ºRAGæŸ¥è¯¢å­—ç¬¦ä¸²"""
        # æå–å…³é”®ç»„ä»¶
        node_labels = [n.data.label for n in nodes[:5]]

        # æå–èŠ‚ç‚¹ç±»å‹
        node_types = list(set([n.type for n in nodes if n.type]))

        query = f"Architecture with {len(nodes)} components: "
        query += ", ".join(node_labels)
        query += f". Types: {', '.join(node_types)}"

        return query

    def post_process_script(self, script: str, duration: str) -> str:
        """
        åå¤„ç†æ¼”è®²ç¨¿

        Args:
            script: åŸå§‹è„šæœ¬ï¼ˆåŒ…å« [INTRO]ã€[BODY]ã€[CONCLUSION] æ ‡è®°ï¼‰
            duration: æ—¶é•¿

        Returns:
            str: å¤„ç†åçš„æ¼”è®²ç¨¿ï¼ˆä¿ç•™å®Œæ•´å†…å®¹ï¼‰
        """
        # ç§»é™¤markdownæ ‡è®°
        script = script.replace("[INTRO]\n", "").replace("[BODY]\n", "").replace("[CONCLUSION]\n", "")
        script = script.replace("[INTRO]", "").replace("[BODY]", "").replace("[CONCLUSION]", "")

        # æ¸…ç†å¤šä¸ªè¿ç»­ç©ºè¡Œï¼ˆæ›¿æ¢ä¸ºæœ€å¤š2ä¸ªæ¢è¡Œï¼‰
        import re
        script = re.sub(r'\n{3,}', '\n\n', script)

        return script.strip()

    def estimate_duration(self, script: str) -> int:
        """
        ä¼°ç®—æ¼”è®²æ—¶é•¿ï¼ˆç§’æ•°ï¼‰

        Args:
            script: æ¼”è®²ç¨¿æ–‡æœ¬

        Returns:
            int: é¢„ä¼°æ—¶é•¿ï¼ˆç§’ï¼‰
        """
        word_count = self._count_words(script)

        # å¹³å‡æ¯åˆ†é’Ÿ150å­—
        minutes = word_count / 150
        seconds = int(minutes * 60)

        return seconds

    def _count_words(self, text: str) -> int:
        """
        æ™ºèƒ½è®¡ç®—ä¸­è‹±æ–‡æ··åˆæ–‡æœ¬çš„å­—æ•°

        ä¸­æ–‡å­—ç¬¦è®¡ä¸º1ä¸ªå­—ï¼Œè‹±æ–‡å•è¯è®¡ä¸º1ä¸ªè¯

        Args:
            text: æ–‡æœ¬å†…å®¹

        Returns:
            int: å­—æ•°
        """
        import re

        # ç§»é™¤æ‰€æœ‰ç©ºç™½å­—ç¬¦
        text_no_space = re.sub(r'\s+', '', text)

        # åˆ†ç¦»ä¸­æ–‡å­—ç¬¦å’Œè‹±æ–‡å•è¯
        # ä¸­æ–‡å­—ç¬¦èŒƒå›´ï¼š\u4e00-\u9fff
        chinese_chars = re.findall(r'[\u4e00-\u9fff]', text_no_space)
        chinese_count = len(chinese_chars)

        # è‹±æ–‡å•è¯ï¼ˆè¿ç»­çš„è‹±æ–‡å­—æ¯ï¼‰
        english_words = re.findall(r'[a-zA-Z]+', text)
        english_count = len(english_words)

        # æ•°å­—å’Œç¬¦å·ä¸è®¡å…¥å­—æ•°
        total = chinese_count + english_count

        return total

    def _get_target_words(self, duration: str) -> int:
        """è·å–ç›®æ ‡å­—æ•°"""
        targets = {
            "30s": 140,
            "2min": 600,
            "5min": 1500
        }
        return targets.get(duration, 600)

    def extract_section(self, accumulated: str, section: str) -> str:
        """æå–ç‰¹å®šç« èŠ‚"""
        if section == "intro":
            if "[BODY]" in accumulated:
                return accumulated.split("[BODY]")[0].replace("[INTRO]", "").strip()
        elif section == "body":
            if "[BODY]" in accumulated and "[CONCLUSION]" in accumulated:
                body_part = accumulated.split("[BODY]")[1]
                return body_part.split("[CONCLUSION]")[0].strip()
        elif section == "conclusion":
            if "[CONCLUSION]" in accumulated:
                return accumulated.split("[CONCLUSION]")[1].strip()

        return ""

    def _split_into_sections(self, script: str) -> dict:
        """å°†æ¼”è®²ç¨¿åˆ†å‰²ä¸ºä¸‰ä¸ªç« èŠ‚"""
        # ç®€å•ç­–ç•¥ï¼šæŒ‰æ®µè½æ•°é‡åˆ†å‰²
        paragraphs = [p.strip() for p in script.split("\n\n") if p.strip()]

        if len(paragraphs) <= 3:
            return {
                "intro": paragraphs[0] if len(paragraphs) > 0 else "",
                "body": paragraphs[1] if len(paragraphs) > 1 else "",
                "conclusion": paragraphs[2] if len(paragraphs) > 2 else ""
            }

        # æŒ‰æ¯”ä¾‹åˆ†å‰²ï¼šå¼€åœº20%ï¼Œä¸»ä½“60%ï¼Œç»“å°¾20%
        total = len(paragraphs)
        intro_end = max(1, int(total * 0.2))
        body_end = max(intro_end + 1, int(total * 0.8))

        return {
            "intro": "\n\n".join(paragraphs[:intro_end]),
            "body": "\n\n".join(paragraphs[intro_end:body_end]),
            "conclusion": "\n\n".join(paragraphs[body_end:])
        }

    def _generate_mock_script(
        self,
        nodes: List[Node],
        edges: List[Edge],
        duration: str
    ) -> str:
        """ç”Ÿæˆmockæ¼”è®²ç¨¿ï¼ˆç”¨äºæµ‹è¯•ï¼‰"""
        node_count = len(nodes)
        edge_count = len(edges)

        if duration == "30s":
            return f"""[INTRO]
æƒ³è±¡ä¸€ä¸‹ï¼Œå½“ç³»ç»Ÿé¢ä¸´{node_count}ä¸ªå…³é”®ç»„ä»¶çš„ååŒæŒ‘æˆ˜æ—¶ï¼Œå¦‚ä½•ç¡®ä¿é«˜å¯ç”¨æ€§ï¼Ÿä»Šå¤©æˆ‘æƒ³åˆ†äº«æˆ‘ä»¬çš„æ¶æ„è®¾è®¡æ–¹æ¡ˆã€‚

[BODY]
æˆ‘ä»¬çš„æ¶æ„åŒ…å«{node_count}ä¸ªæ ¸å¿ƒç»„ä»¶ï¼Œé€šè¿‡{edge_count}ä¸ªå…³é”®è¿æ¥å®ç°æ•°æ®æµè½¬ã€‚æ ¸å¿ƒè®¾è®¡ç†å¿µæ˜¯æ¨¡å—åŒ–å’Œè§£è€¦ï¼Œæ¯ä¸ªç»„ä»¶èŒè´£æ¸…æ™°ï¼Œä¾¿äºæ‰©å±•å’Œç»´æŠ¤ã€‚

[CONCLUSION]
è¿™å¥—æ¶æ„ä¸ä»…è§£å†³äº†å½“å‰é—®é¢˜ï¼Œæ›´ä¸ºæœªæ¥å¢é•¿é¢„ç•™äº†ç©ºé—´ã€‚æ¬¢è¿äº¤æµè®¨è®ºï¼"""

        elif duration == "2min":
            components = ", ".join([n.data.label for n in nodes[:3]])
            return f"""[INTRO]
åœ¨å½“ä»Šå¿«é€Ÿå‘å±•çš„æŠ€æœ¯ç¯å¢ƒä¸­ï¼Œç³»ç»Ÿæ¶æ„é¢ä¸´ç€å‰æ‰€æœªæœ‰çš„æŒ‘æˆ˜ã€‚æˆ‘ä»¬çš„ç³»ç»ŸåŒ…å«{node_count}ä¸ªç»„ä»¶ï¼Œå¦‚ä½•ç¡®ä¿å®ƒä»¬é«˜æ•ˆåä½œï¼Ÿä»Šå¤©ï¼Œæˆ‘æƒ³åˆ†äº«æˆ‘ä»¬åœ¨æ¶æ„è®¾è®¡ä¸Šçš„å®è·µå’Œæ€è€ƒã€‚

[BODY]
é¦–å…ˆï¼Œè®©æˆ‘ä»‹ç»ä¸€ä¸‹æ¶æ„çš„æ ¸å¿ƒç»„ä»¶ã€‚æˆ‘ä»¬æœ‰{components}ç­‰{node_count}ä¸ªå…³é”®æ¨¡å—ï¼Œå®ƒä»¬é€šè¿‡{edge_count}ä¸ªç²¾å¿ƒè®¾è®¡çš„è¿æ¥ç‚¹è¿›è¡Œæ•°æ®äº¤æ¢ã€‚

åœ¨è®¾è®¡è¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬éµå¾ªäº†å‡ ä¸ªæ ¸å¿ƒåŸåˆ™ï¼šç¬¬ä¸€ï¼Œé«˜å†…èšä½è€¦åˆï¼Œç¡®ä¿æ¯ä¸ªç»„ä»¶èŒè´£å•ä¸€ï¼›ç¬¬äºŒï¼Œå¯æ‰©å±•æ€§ä¼˜å…ˆï¼Œä¸ºæœªæ¥å¢é•¿é¢„ç•™ç©ºé—´ï¼›ç¬¬ä¸‰ï¼Œå®¹é”™è®¾è®¡ï¼Œä»»ä½•å•ç‚¹æ•…éšœéƒ½ä¸ä¼šå½±å“æ•´ä½“æœåŠ¡ã€‚

å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬é‡‡ç”¨äº†å¼‚æ­¥æ¶ˆæ¯ä¼ é€’æœºåˆ¶ï¼Œå°†å„ç»„ä»¶è§£è€¦ï¼›ä½¿ç”¨ç¼“å­˜å±‚æå‡æ€§èƒ½ï¼Œå‡å°‘æ•°æ®åº“å‹åŠ›ï¼›éƒ¨ç½²äº†ç›‘æ§å‘Šè­¦ç³»ç»Ÿï¼Œå®æ—¶è¿½è¸ªç³»ç»Ÿå¥åº·çŠ¶æ€ã€‚

é€šè¿‡è¿™å¥—æ¶æ„ï¼Œæˆ‘ä»¬å®ç°äº†99.9%çš„å¯ç”¨æ€§ï¼Œå“åº”æ—¶é—´ä»åŸæ¥çš„500msé™ä½åˆ°100msä»¥å†…ï¼Œæˆæœ¬èŠ‚çœäº†30%ã€‚

[CONCLUSION]
æ€»ç»“ä¸€ä¸‹ï¼Œå¥½çš„æ¶æ„ä¸æ˜¯ä¸€è¹´è€Œå°±çš„ï¼Œè€Œæ˜¯åœ¨å®è·µä¸­ä¸æ–­æ¼”è¿›çš„ã€‚æˆ‘ä»¬çš„ç»éªŒæ˜¯ï¼šä»ç®€å•å¼€å§‹ï¼ŒæŒç»­ä¼˜åŒ–ï¼Œå§‹ç»ˆå…³æ³¨ä¸šåŠ¡ä»·å€¼ã€‚å¦‚æœä½ ä¹Ÿé¢ä¸´ç±»ä¼¼æŒ‘æˆ˜ï¼Œæ¬¢è¿ä¼šåäº¤æµã€‚è°¢è°¢å¤§å®¶ï¼"""

        else:  # 5min
            return f"""[INTRO]
å„ä½åŒäº‹ï¼Œå¤§å®¶å¥½ï¼ä»Šå¤©æˆ‘æƒ³å’Œå¤§å®¶åˆ†äº«ä¸€ä¸ªæˆ‘ä»¬å›¢é˜Ÿåœ¨è¿‡å»å…­ä¸ªæœˆä¸­å®Œæˆçš„æ¶æ„å‡çº§é¡¹ç›®ã€‚è¿™ä¸ªé¡¹ç›®ä¸ä»…è§£å†³äº†æ€§èƒ½ç“¶é¢ˆï¼Œæ›´é‡è¦çš„æ˜¯ï¼Œå®ƒä¸ºæˆ‘ä»¬æœªæ¥çš„ä¸šåŠ¡å¢é•¿å¥ å®šäº†åšå®çš„æŠ€æœ¯åŸºç¡€ã€‚

è®©æˆ‘å…ˆä»ä¸€ä¸ªåœºæ™¯è¯´èµ·ã€‚å»å¹´åŒ11æœŸé—´ï¼Œå½“ç”¨æˆ·æµé‡çªå¢åˆ°å¹³æ—¶çš„10å€æ—¶ï¼Œæˆ‘ä»¬çš„ç³»ç»Ÿå¼€å§‹å‡ºç°å“åº”ç¼“æ…¢ï¼Œç”šè‡³éƒ¨åˆ†æœåŠ¡ä¸å¯ç”¨ã€‚è¿™æ¬¡äº‹æ•…è®©æˆ‘ä»¬æ„è¯†åˆ°ï¼ŒåŸæœ‰çš„æ¶æ„å·²ç»æ— æ³•æ”¯æ’‘ä¸šåŠ¡çš„å¿«é€Ÿå‘å±•ï¼Œå¿…é¡»è¿›è¡Œå½»åº•çš„é‡æ„ã€‚

[BODY]
åœ¨æ·±å…¥åˆ†æåï¼Œæˆ‘ä»¬å‘ç°äº†å‡ ä¸ªæ ¸å¿ƒé—®é¢˜ï¼šç¬¬ä¸€ï¼Œå•ä½“åº”ç”¨æ¶æ„å¯¼è‡´ä»»ä½•å°æ”¹åŠ¨éƒ½éœ€è¦æ•´ä½“é‡å¯ï¼›ç¬¬äºŒï¼Œæ•°æ®åº“æˆä¸ºæ€§èƒ½ç“¶é¢ˆï¼ŒæŸ¥è¯¢å“åº”æ—¶é—´éšç€æ•°æ®é‡å¢é•¿æ€¥å‰§ä¸Šå‡ï¼›ç¬¬ä¸‰ï¼Œç¼ºä¹æœ‰æ•ˆçš„ç¼“å­˜æœºåˆ¶ï¼Œå¤§é‡é‡å¤è®¡ç®—æµªè´¹èµ„æºã€‚

åŸºäºè¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬è®¾è®¡äº†å…¨æ–°çš„æ¶æ„ã€‚è¿™ä¸ªæ¶æ„åŒ…å«{node_count}ä¸ªæ ¸å¿ƒç»„ä»¶ï¼Œé€šè¿‡{edge_count}ä¸ªæ¸…æ™°å®šä¹‰çš„æ¥å£è¿›è¡Œäº¤äº’ã€‚æ ¸å¿ƒè®¾è®¡ç†å¿µæœ‰ä¸‰ç‚¹ï¼šç¬¬ä¸€ï¼Œå¾®æœåŠ¡åŒ–ï¼Œå°†å•ä½“åº”ç”¨æ‹†åˆ†ä¸ºç‹¬ç«‹çš„æœåŠ¡å•å…ƒï¼›ç¬¬äºŒï¼Œå¤šçº§ç¼“å­˜ï¼Œä»è¾¹ç¼˜åˆ°æ•°æ®åº“å»ºç«‹å®Œæ•´çš„ç¼“å­˜ä½“ç³»ï¼›ç¬¬ä¸‰ï¼Œå¼‚æ­¥åŒ–ï¼Œéå…³é”®è·¯å¾„å…¨éƒ¨å¼‚æ­¥å¤„ç†ï¼Œæå‡å“åº”é€Ÿåº¦ã€‚

è®©æˆ‘è¯¦ç»†ä»‹ç»å‡ ä¸ªå…³é”®ç»„ä»¶ã€‚{nodes[0].data.label if nodes else 'æ ¸å¿ƒç»„ä»¶'}è´Ÿè´£ä¸šåŠ¡é€»è¾‘å¤„ç†ï¼Œé‡‡ç”¨æ— çŠ¶æ€è®¾è®¡ï¼Œå¯ä»¥æ°´å¹³æ‰©å±•ã€‚æˆ‘ä»¬é€‰æ‹©è¿™ä¸ªæ–¹æ¡ˆè€Œä¸æ˜¯ä¼ ç»Ÿçš„æœ‰çŠ¶æ€æœåŠ¡ï¼Œæ˜¯å› ä¸ºæ— çŠ¶æ€è®¾è®¡åœ¨äº‘ç¯å¢ƒä¸‹æ›´å®¹æ˜“å®ç°è‡ªåŠ¨ä¼¸ç¼©ï¼Œè¿ç»´æˆæœ¬æ›´ä½ã€‚

{nodes[1].data.label if len(nodes) > 1 else 'æ•°æ®å±‚'}ä½¿ç”¨äº†è¯»å†™åˆ†ç¦»å’Œåˆ†åº“åˆ†è¡¨ç­–ç•¥ã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼Œæˆ‘ä»¬å°†å•åº“çš„å‹åŠ›åˆ†æ•£åˆ°å¤šä¸ªå®ä¾‹ï¼ŒæŸ¥è¯¢æ€§èƒ½æå‡äº†5å€ã€‚åŒæ—¶ï¼Œæˆ‘ä»¬å¼•å…¥äº†Redisä½œä¸ºç¼“å­˜å±‚ï¼Œå‘½ä¸­ç‡è¾¾åˆ°95%ï¼Œå¤§å¹…å‡è½»äº†æ•°æ®åº“è´Ÿæ‹…ã€‚

åœ¨æ•°æ®æµæ–¹é¢ï¼Œæˆ‘ä»¬å»ºç«‹äº†ä¸€å¥—å®Œæ•´çš„å¼‚æ­¥æ¶ˆæ¯ç³»ç»Ÿã€‚æ‰€æœ‰éå®æ—¶çš„æ“ä½œï¼Œå¦‚æ—¥å¿—è®°å½•ã€æ•°æ®ç»Ÿè®¡ã€é€šçŸ¥å‘é€ç­‰ï¼Œéƒ½é€šè¿‡æ¶ˆæ¯é˜Ÿåˆ—å¼‚æ­¥å¤„ç†ã€‚è¿™ä¸ä»…æå‡äº†ç”¨æˆ·ä½“éªŒï¼Œä¹Ÿè®©ç³»ç»Ÿæ›´åŠ å¥å£®ã€‚å³ä½¿ä¸‹æ¸¸æœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼Œæ¶ˆæ¯ä¹Ÿä¼šè¢«æŒä¹…åŒ–ä¿å­˜ï¼Œå¾…æ¢å¤åç»§ç»­å¤„ç†ã€‚

å½“ç„¶ï¼Œä»»ä½•æ¶æ„éƒ½ä¸æ˜¯å®Œç¾çš„ï¼Œæˆ‘ä»¬ä¹Ÿé¢ä¸´ä¸€äº›æŒ‘æˆ˜ã€‚æ¯”å¦‚ï¼Œå¾®æœåŠ¡å¸¦æ¥çš„åˆ†å¸ƒå¼äº‹åŠ¡é—®é¢˜ï¼Œæˆ‘ä»¬é‡‡ç”¨äº†æœ€ç»ˆä¸€è‡´æ€§æ–¹æ¡ˆï¼Œé€šè¿‡è¡¥å¿æœºåˆ¶ç¡®ä¿æ•°æ®æ­£ç¡®æ€§ã€‚å†æ¯”å¦‚ï¼ŒæœåŠ¡é—´è°ƒç”¨é“¾è·¯å˜é•¿ï¼Œå¯èƒ½å¯¼è‡´å»¶è¿Ÿç´¯ç§¯ï¼Œæˆ‘ä»¬é€šè¿‡ç†”æ–­é™çº§æœºåˆ¶æ¥ä¿æŠ¤ç³»ç»Ÿç¨³å®šæ€§ã€‚

ä»å®æ–½æ•ˆæœæ¥çœ‹ï¼Œæ–°æ¶æ„å¸¦æ¥çš„æ”¹è¿›éå¸¸æ˜æ˜¾ã€‚ç³»ç»Ÿå¯ç”¨æ€§ä»95%æå‡åˆ°99.9%ï¼Œå“åº”æ—¶é—´ä¸­ä½æ•°ä»500msé™ä½åˆ°80msï¼Œåœ¨åŒ11æœŸé—´è½»æ¾æ”¯æ’‘äº†3å€äºå»å¹´çš„æµé‡ã€‚æ›´é‡è¦çš„æ˜¯ï¼Œå¼€å‘æ•ˆç‡æå‡äº†50%ï¼Œå›¢é˜Ÿå¯ä»¥ç‹¬ç«‹å¹¶è¡Œå¼€å‘ä¸åŒçš„æœåŠ¡æ¨¡å—ï¼Œéƒ¨ç½²é¢‘ç‡ä»æ¯å‘¨ä¸€æ¬¡æå‡åˆ°æ¯å¤©å¤šæ¬¡ã€‚

[CONCLUSION]
æ€»ç»“ä¸€ä¸‹ä»Šå¤©åˆ†äº«çš„æ ¸å¿ƒè¦ç‚¹ã€‚ç¬¬ä¸€ï¼Œæ¶æ„è®¾è®¡è¦ä»ä¸šåŠ¡ç—›ç‚¹å‡ºå‘ï¼Œä¸è¦ä¸ºäº†æŠ€æœ¯è€ŒæŠ€æœ¯ã€‚ç¬¬äºŒï¼Œæ²¡æœ‰é“¶å¼¹ï¼Œæ¯ç§æ–¹æ¡ˆéƒ½æœ‰trade-offï¼Œè¦æ ¹æ®å®é™…æƒ…å†µé€‰æ‹©ã€‚ç¬¬ä¸‰ï¼Œæ¶æ„æ˜¯æ¼”è¿›çš„ï¼Œä»ç®€å•å¼€å§‹ï¼ŒæŒç»­ä¼˜åŒ–ï¼Œä¸è¦è¿½æ±‚ä¸€æ­¥åˆ°ä½ã€‚

å±•æœ›æœªæ¥ï¼Œæˆ‘ä»¬è®¡åˆ’å¼•å…¥æœåŠ¡ç½‘æ ¼æŠ€æœ¯ï¼Œè¿›ä¸€æ­¥ç®€åŒ–æœåŠ¡é—´é€šä¿¡ï¼›åŒæ—¶æ¢ç´¢è¾¹ç¼˜è®¡ç®—ï¼Œå°†è®¡ç®—èƒ½åŠ›ä¸‹æ²‰åˆ°ç¦»ç”¨æˆ·æ›´è¿‘çš„åœ°æ–¹ã€‚

æœ€åï¼Œæˆ‘æƒ³ç•™å‡ ä¸ªé—®é¢˜ç»™å¤§å®¶æ€è€ƒï¼šç¬¬ä¸€ï¼Œåœ¨ä½ ä»¬çš„åœºæ™¯ä¸­ï¼Œå¦‚ä½•å¹³è¡¡ç³»ç»Ÿå¤æ‚åº¦å’Œå¯ç»´æŠ¤æ€§ï¼Ÿç¬¬äºŒï¼Œå¾®æœåŠ¡æ‹†åˆ†çš„ç²’åº¦å¦‚ä½•æŠŠæ¡ï¼Ÿç¬¬ä¸‰ï¼Œå¦‚ä½•å»ºç«‹æœ‰æ•ˆçš„ç›‘æ§ä½“ç³»æ¥ä¿éšœåˆ†å¸ƒå¼ç³»ç»Ÿçš„ç¨³å®šæ€§ï¼Ÿ

å¦‚æœå¤§å®¶å¯¹è¿™äº›è¯é¢˜æ„Ÿå…´è¶£ï¼Œæ¬¢è¿ä¼šåäº¤æµã€‚æˆ‘çš„è”ç³»æ–¹å¼åœ¨æœ€åä¸€é¡µï¼ŒæœŸå¾…å’Œå¤§å®¶æ·±å…¥æ¢è®¨ã€‚è°¢è°¢å¤§å®¶çš„è†å¬ï¼"""


# ============================================================
# Service Factory (Singleton Pattern)
# ============================================================

# ä¸å†ä½¿ç”¨å•ä¾‹æ¨¡å¼ï¼Œæ¯æ¬¡è°ƒç”¨éƒ½åˆ›å»ºæ–°å®ä¾‹ä»¥æ”¯æŒä¸åŒçš„providerå’Œapi_key


def get_rag_speech_script_generator(
    provider: str = "gemini",
    api_key: Optional[str] = None,
    base_url: Optional[str] = None,
    model_name: Optional[str] = None
) -> RAGSpeechScriptGenerator:
    """
    Get RAGSpeechScriptGenerator instance with AI service

    Args:
        provider: AI provider (gemini, openai, claude, siliconflow, custom)
        api_key: API key for the provider
        base_url: Base URL for custom provider
        model_name: Model name for the provider

    Returns:
        RAGSpeechScriptGenerator instance with AI service configured
    """
    from app.services.ai_vision import create_vision_service

    # åˆ›å»ºAIè§†è§‰æœåŠ¡ï¼Œä¼ é€’æ‰€æœ‰é…ç½®å‚æ•°
    ai_service = create_vision_service(
        provider=provider,
        api_key=api_key,
        base_url=base_url,
        model_name=model_name
    )

    # åˆ›å»ºRAGæ¼”è®²ç¨¿ç”Ÿæˆå™¨ï¼ˆæš‚æ—¶ä¸é›†æˆRAGæœåŠ¡ï¼‰
    generator = RAGSpeechScriptGenerator(rag_service=None, ai_service=ai_service)

    logger.info(f"Created RAGSpeechScriptGenerator with provider: {provider}, model: {model_name or 'default'}")
    return generator
