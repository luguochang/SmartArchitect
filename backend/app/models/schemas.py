from pydantic import BaseModel, Field
from typing import List, Optional, Literal


# React Flow èŠ‚ç‚¹å’Œè¾¹çš„æ•°æ®æ¨¡å‹
class NodeData(BaseModel):
    label: str
    shape: Optional[Literal["rectangle", "circle", "diamond", "start-event", "end-event", "intermediate-event", "task"]] = None
    iconType: Optional[str] = None  # Icon identifier (e.g., "play-circle", "stop-circle")
    color: Optional[str] = None  # Color class or value


class Position(BaseModel):
    x: float
    y: float


class Node(BaseModel):
    id: str
    type: Optional[str] = "default"
    position: Position
    data: NodeData


class Edge(BaseModel):
    id: str
    source: str
    target: str
    label: Optional[str] = None


class GraphData(BaseModel):
    nodes: List[Node]
    edges: List[Edge]


# Mermaid è½¬æ¢ç›¸å…³
class MermaidParseRequest(BaseModel):
    code: str = Field(..., description="Mermaid ä»£ç ")


class MermaidParseResponse(BaseModel):
    nodes: List[Node]
    edges: List[Edge]
    success: bool = True
    message: Optional[str] = None


class GraphToMermaidRequest(BaseModel):
    nodes: List[Node]
    edges: List[Edge]


class GraphToMermaidResponse(BaseModel):
    mermaid_code: str
    success: bool = True


# AI æ¨¡å‹é…ç½®
class ModelConfig(BaseModel):
    provider: Literal["gemini", "openai", "claude", "siliconflow", "custom"]
    api_key: str
    model_name: str
    base_url: Optional[str] = None


class ModelConfigResponse(BaseModel):
    success: bool
    message: str


# æ¨¡å‹é¢„è®¾é…ç½®ï¼ˆæ”¯æŒä¿å­˜å¤šä¸ªé…ç½®ï¼‰
class ModelPreset(BaseModel):
    id: str  # é¢„è®¾IDï¼ˆå¦‚ "my-gemini", "company-openai"ï¼‰
    name: str  # æ˜¾ç¤ºåç§°ï¼ˆå¦‚ "ä¸ªäºº Gemini", "å…¬å¸ OpenAI"ï¼‰
    provider: Literal["gemini", "openai", "claude", "siliconflow", "custom"]
    api_key: str
    model_name: str
    base_url: Optional[str] = None
    is_default: bool = False  # æ˜¯å¦ä¸ºé»˜è®¤é…ç½®
    created_at: Optional[str] = None
    updated_at: Optional[str] = None


class ModelPresetCreate(BaseModel):
    name: str
    provider: Literal["gemini", "openai", "claude", "siliconflow", "custom"]
    api_key: str
    model_name: str
    base_url: Optional[str] = None
    is_default: bool = False


class ModelPresetUpdate(BaseModel):
    name: Optional[str] = None
    api_key: Optional[str] = None
    model_name: Optional[str] = None
    base_url: Optional[str] = None
    is_default: Optional[bool] = None


class ModelPresetListResponse(BaseModel):
    success: bool
    presets: List[ModelPreset]


class ModelPresetResponse(BaseModel):
    success: bool
    preset: Optional[ModelPreset] = None
    message: Optional[str] = None


# ========== Phase 2: å›¾ç‰‡åˆ†æå’Œæ¶æ„ä¼˜åŒ– ==========

# æ¶æ„ç“¶é¢ˆ
class ArchitectureBottleneck(BaseModel):
    node_id: str
    type: Literal["single_point_of_failure", "performance_bottleneck",
                   "scalability_issue", "security_concern"]
    severity: Literal["low", "medium", "high", "critical"]
    description: str
    recommendation: str


# ä¼˜åŒ–å»ºè®®
class OptimizationSuggestion(BaseModel):
    id: str
    title: str
    description: str
    bottlenecks: List[ArchitectureBottleneck]
    optimized_nodes: List[Node]
    optimized_edges: List[Edge]
    optimized_mermaid: str
    impact: Literal["low", "medium", "high"]


# AI åˆ†æç»“æœ
class AIAnalysis(BaseModel):
    bottlenecks: List[ArchitectureBottleneck] = []
    suggestions: List[OptimizationSuggestion] = []
    confidence: Optional[float] = None
    model_used: Optional[str] = None


# å›¾ç‰‡åˆ†æå“åº”
class ImageAnalysisResponse(BaseModel):
    nodes: List[Node]
    edges: List[Edge]
    mermaid_code: str
    success: bool = True
    message: Optional[str] = None
    ai_analysis: Optional[AIAnalysis] = None

    # Phase 6: æµç¨‹å›¾è¯†åˆ«ä¸“ç”¨å­—æ®µ
    warnings: Optional[List[dict]] = None  # è¯†åˆ«è­¦å‘Šï¼ˆå¦‚ï¼šå½¢çŠ¶æ˜ å°„ï¼‰
    flowchart_analysis: Optional[dict] = None  # æµç¨‹å›¾åˆ†æï¼ˆå¤æ‚åº¦ã€ç±»å‹ç­‰ï¼‰


# æ¶æ„ä¼˜åŒ–åˆ†æè¯·æ±‚
class OptimizationAnalysisRequest(BaseModel):
    nodes: List[Node]
    edges: List[Edge]


# æ¶æ„ä¼˜åŒ–åˆ†æå“åº”
class OptimizationAnalysisResponse(BaseModel):
    suggestions: List[OptimizationSuggestion]
    success: bool = True
    message: Optional[str] = None


# ========== Phase 3: Prompter ç³»ç»Ÿ ==========

# Prompter åœºæ™¯é¢„è®¾
class PromptScenario(BaseModel):
    id: str
    name: str
    description: str
    system_prompt: str
    user_prompt_template: str
    category: Literal["refactoring", "security", "beautification", "custom"]
    icon: Optional[str] = None
    is_default: bool = False


# Prompter åœºæ™¯åˆ—è¡¨
class PromptScenarioList(BaseModel):
    scenarios: List[PromptScenario]


# Prompter æ‰§è¡Œè¯·æ±‚
class PromptExecutionRequest(BaseModel):
    scenario_id: str
    nodes: List[Node]
    edges: List[Edge]
    user_input: Optional[str] = None
    mermaid_code: Optional[str] = None


# Prompter æ‰§è¡Œå“åº”
class PromptExecutionResponse(BaseModel):
    nodes: List[Node]
    edges: List[Edge]
    mermaid_code: str
    ai_explanation: str
    success: bool = True
    message: Optional[str] = None


# ============================================================
# Phase 4: RAG Knowledge Base
# ============================================================

# Document metadata
class DocumentMetadata(BaseModel):
    filename: str
    file_type: Literal["pdf", "markdown", "docx"]
    upload_date: str
    num_chunks: int


# Document upload response
class DocumentUploadResponse(BaseModel):
    document_id: str
    chunks_created: int
    success: bool = True
    message: Optional[str] = None


# Document search request
class DocumentSearchRequest(BaseModel):
    query: str
    top_k: int = Field(default=5, ge=1, le=20)


# Document chunk in search results
class DocumentChunk(BaseModel):
    chunk_id: str
    content: str
    score: float
    metadata: DocumentMetadata


# Document search response
class DocumentSearchResponse(BaseModel):
    chunks: List[DocumentChunk]
    query: str
    success: bool = True


# ============================================================
# Phase 4: Export Features
# ============================================================

# Export request for PPT/Slidev
class ExportRequest(BaseModel):
    nodes: List[Node]
    edges: List[Edge]
    mermaid_code: str
    title: Optional[str] = "Architecture Diagram"


# Speech script generation request
class SpeechScriptRequest(BaseModel):
    nodes: List[Node]
    edges: List[Edge]
    duration: Literal["30s", "2min", "5min"]


# Speech script response
class SpeechScriptResponse(BaseModel):
    script: str
    duration: str
    word_count: int
    success: bool = True


# ============================================================
# Phase 5: Chat Generator (Flowchart from Natural Language)
# ============================================================

# Flow template for quick start
class FlowTemplate(BaseModel):
    id: str
    name: str
    description: str
    category: Literal["architecture", "troubleshooting", "business", "algorithm", "devops"]
    example_input: str
    icon: Optional[str] = None


# Template list response
class FlowTemplateList(BaseModel):
    templates: List[FlowTemplate]


# Chat generation request
class ChatGenerationRequest(BaseModel):
    user_input: str
    template_id: Optional[str] = None
    provider: Optional[Literal["gemini", "openai", "claude", "siliconflow", "custom"]] = "gemini"
    diagram_type: Literal["flow", "architecture"] = "flow"
    architecture_type: Optional[Literal["layered", "business", "technical", "deployment", "domain"]] = "layered"
    api_key: Optional[str] = None
    base_url: Optional[str] = None
    model_name: Optional[str] = None

    # ğŸ†• å¢é‡ç”Ÿæˆå‚æ•°
    incremental_mode: Optional[bool] = False  # æ˜¯å¦å¯ç”¨å¢é‡æ¨¡å¼
    session_id: Optional[str] = None  # ä¼šè¯ IDï¼ˆç”¨äºè·å–ç°æœ‰ç”»æ¿ï¼‰


# Chat generation response
class ChatGenerationResponse(BaseModel):
    nodes: List[Node]
    edges: List[Edge]
    mermaid_code: str
    success: bool = True
    message: Optional[str] = None
    session_id: Optional[str] = None  # ğŸ†• è¿”å›ä¼šè¯ IDï¼ˆä¾›å‰ç«¯åç»­ä½¿ç”¨ï¼‰


# ============================================================
# Canvas Session Management (å¢é‡ç”Ÿæˆä¼šè¯ç®¡ç†)
# ============================================================

# Canvas session save request
class CanvasSaveRequest(BaseModel):
    session_id: Optional[str] = None  # å¯é€‰ï¼Œç©ºåˆ™åˆ›å»ºæ–°ä¼šè¯
    nodes: List[Node]
    edges: List[Edge]


# Canvas session save response
class CanvasSaveResponse(BaseModel):
    success: bool = True
    session_id: str
    message: Optional[str] = None
    node_count: int
    edge_count: int


# Canvas session data
class CanvasSessionData(BaseModel):
    nodes: List[Node]
    edges: List[Edge]
    node_count: int
    edge_count: int
    timestamp: str
    created_at: str


# Canvas session get response
class CanvasSessionResponse(BaseModel):
    success: bool = True
    session: Optional[CanvasSessionData] = None
    message: Optional[str] = None


# Canvas session delete response
class CanvasSessionDeleteResponse(BaseModel):
    success: bool = True
    message: str


# ============================================================
# Excalidraw Generation
# ============================================================


class ExcalidrawGenerateRequest(BaseModel):
    prompt: str
    style: Optional[str] = None
    width: Optional[int] = 1200
    height: Optional[int] = 800
    provider: Optional[Literal["gemini", "openai", "claude", "siliconflow", "custom"]] = "custom"
    api_key: Optional[str] = None
    base_url: Optional[str] = None
    model_name: Optional[str] = None


class ExcalidrawScene(BaseModel):
    elements: List[dict]
    appState: dict = Field(default_factory=dict)
    files: dict = Field(default_factory=dict)


class ExcalidrawGenerateResponse(BaseModel):
    scene: ExcalidrawScene
    success: bool = True
    message: Optional[str] = None


# ============================================================
# Phase 1 Enhancement: Professional Speech Script Generation
# ============================================================

# Script generation options
class ScriptOptions(BaseModel):
    tone: Literal["professional", "casual", "technical"] = "professional"
    audience: Literal["executive", "technical", "mixed"] = "mixed"
    focus_areas: List[str] = Field(default_factory=lambda: ["scalability", "performance"])


# Script content sections
class ScriptContent(BaseModel):
    intro: str
    body: str
    conclusion: str
    full_text: str


# Script metadata
class ScriptMetadata(BaseModel):
    created_at: Optional[str] = None
    updated_at: Optional[str] = None
    duration: Literal["30s", "2min", "5min"]
    word_count: int = 0
    rag_sources: List[str] = Field(default_factory=list)
    architecture_snapshot: Optional[dict] = None
    version: int = 0


# Script draft (for editing and saving)
class ScriptDraft(BaseModel):
    id: str
    content: ScriptContent
    metadata: ScriptMetadata
    version: int = 1


# Stream event for SSE
class StreamEvent(BaseModel):
    type: Literal["CONTEXT_SEARCH", "CONTEXT_FOUND", "GENERATION_START",
                  "TOKEN", "SECTION_COMPLETE", "COMPLETE", "ERROR"]
    data: dict = Field(default_factory=dict)


# Save draft response
class SaveDraftResponse(BaseModel):
    script_id: str
    version: int
    saved_at: str
    success: bool = True


# Refine section response
class RefinedSectionResponse(BaseModel):
    script_id: str
    section: Literal["intro", "body", "conclusion"]
    refined_text: str
    changes_summary: str
    success: bool = True


# Improvement suggestion
class ImprovementSuggestion(BaseModel):
    section: Literal["intro", "body", "conclusion", "overall"]
    issue: str
    suggestion: str
    priority: Literal["high", "medium", "low"]


# Improvement suggestions response
class ImprovementSuggestions(BaseModel):
    overall_score: float = Field(..., ge=0.0, le=10.0)
    strengths: List[str] = Field(default_factory=list)
    weaknesses: List[str] = Field(default_factory=list)
    suggestions: List[ImprovementSuggestion] = Field(default_factory=list)
    success: bool = True


# Enhanced speech script request (with RAG support)
class EnhancedSpeechScriptRequest(BaseModel):
    nodes: List[Node]
    edges: List[Edge]
    duration: Literal["30s", "2min", "5min"]
    options: ScriptOptions = Field(default_factory=ScriptOptions)


# ========== Vision to Diagram: å›¾ç‰‡è½¬æµç¨‹å›¾/æ¶æ„å›¾ ==========

# Vision to Excalidraw request
class VisionToExcalidrawRequest(BaseModel):
    image_data: str = Field(..., description="Base64 encoded image (with data:image prefix or without)")
    prompt: Optional[str] = Field(None, description="Additional context or instructions")
    provider: Literal["gemini", "openai", "claude", "siliconflow", "custom"] = "custom"
    api_key: Optional[str] = Field(None, description="API key for the provider")
    base_url: Optional[str] = Field(None, description="Base URL for custom provider")
    model_name: Optional[str] = Field(None, description="Model name (e.g., claude-sonnet-4-5-20250929)")
    width: Optional[int] = Field(1200, description="Canvas width")
    height: Optional[int] = Field(800, description="Canvas height")


# Vision to React Flow request
class VisionToReactFlowRequest(BaseModel):
    image_data: str = Field(..., description="Base64 encoded image (with data:image prefix or without)")
    prompt: Optional[str] = Field(None, description="Additional context or instructions")
    provider: Literal["gemini", "openai", "claude", "siliconflow", "custom"] = "custom"
    api_key: Optional[str] = Field(None, description="API key for the provider")
    base_url: Optional[str] = Field(None, description="Base URL for custom provider")
    model_name: Optional[str] = Field(None, description="Model name")
    preserve_layout: bool = Field(True, description="Preserve original node positions")
    fast_mode: bool = Field(True, description="Use fast mode (simplified prompt)")



# Excalidraw element (simplified, compatible with Excalidraw JSON format)
class ExcalidrawElement(BaseModel):
    id: str
    type: Literal["rectangle", "ellipse", "diamond", "arrow", "line", "text", "freedraw", "image"]
    x: float
    y: float
    width: Optional[float] = None
    height: Optional[float] = None
    angle: Optional[float] = 0
    strokeColor: Optional[str] = "#000000"
    backgroundColor: Optional[str] = "#ffffff"
    fillStyle: Optional[str] = "hachure"
    strokeWidth: Optional[int] = 1
    strokeStyle: Optional[str] = "solid"
    roughness: Optional[int] = 1
    opacity: Optional[int] = 100
    points: Optional[List[List[float]]] = None  # For arrows and lines
    text: Optional[str] = None  # For text elements
    fontSize: Optional[int] = 20
    fontFamily: Optional[int] = 1
    textAlign: Optional[str] = "center"
    verticalAlign: Optional[str] = "middle"
    startBinding: Optional[dict] = None
    endBinding: Optional[dict] = None


# Excalidraw scene
class ExcalidrawScene(BaseModel):
    elements: List[dict]  # Use dict to allow flexible Excalidraw schema
    appState: Optional[dict] = Field(default_factory=lambda: {"viewBackgroundColor": "#ffffff"})
    files: Optional[dict] = Field(default_factory=dict)


# Vision to Excalidraw response
class VisionToExcalidrawResponse(BaseModel):
    success: bool
    scene: Optional[ExcalidrawScene] = None
    message: Optional[str] = None
    raw_response: Optional[str] = None  # For debugging


# Vision to React Flow response
class VisionToReactFlowResponse(BaseModel):
    success: bool
    nodes: Optional[List[Node]] = None
    edges: Optional[List[Edge]] = None
    message: Optional[str] = None
    raw_response: Optional[str] = None  # For debugging
